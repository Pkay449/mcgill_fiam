{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **MUST RUN 01-Data_Preprocessing/01-preprocessing_code.py AND 02-Feature_Engineering/01-fe_code.py BEFORE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have the following dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load objects/X_DATASET.pkl and objects/Y_DATASET.pkl\n",
    "X = pd.read_pickle('../objects/X_DATASET.pkl')\n",
    "Y = pd.read_pickle('../objects/Y_DATASET.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>aliq_at</th>\n",
       "      <th>aliq_mat</th>\n",
       "      <th>ami_126d</th>\n",
       "      <th>at_be</th>\n",
       "      <th>at_gr1</th>\n",
       "      <th>at_me</th>\n",
       "      <th>at_turnover</th>\n",
       "      <th>be_gr1a</th>\n",
       "      <th>be_me</th>\n",
       "      <th>...</th>\n",
       "      <th>tax_gr1a</th>\n",
       "      <th>turnover_126d</th>\n",
       "      <th>turnover_var_126d</th>\n",
       "      <th>z_score</th>\n",
       "      <th>zero_trades_126d</th>\n",
       "      <th>zero_trades_21d</th>\n",
       "      <th>zero_trades_252d</th>\n",
       "      <th>log_diff</th>\n",
       "      <th>frac_diff</th>\n",
       "      <th>sadf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>0.985818</td>\n",
       "      <td>0.059472</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.260918</td>\n",
       "      <td>0.651395</td>\n",
       "      <td>0.042021</td>\n",
       "      <td>1.028183</td>\n",
       "      <td>0.310450</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018174</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.336775</td>\n",
       "      <td>43.032362</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23522</th>\n",
       "      <td>600</td>\n",
       "      <td>0.610528</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>2.318300</td>\n",
       "      <td>-0.088342</td>\n",
       "      <td>0.149204</td>\n",
       "      <td>0.845524</td>\n",
       "      <td>-0.035351</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013003</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.472298</td>\n",
       "      <td>10.113916</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75824</th>\n",
       "      <td>325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>11.225380</td>\n",
       "      <td>0.119811</td>\n",
       "      <td>4.214064</td>\n",
       "      <td>0.086138</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.375405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.729098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76014</th>\n",
       "      <td>60</td>\n",
       "      <td>0.616255</td>\n",
       "      <td>0.219590</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>2.971011</td>\n",
       "      <td>0.093083</td>\n",
       "      <td>0.441731</td>\n",
       "      <td>1.506417</td>\n",
       "      <td>0.083045</td>\n",
       "      <td>0.148680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.509687</td>\n",
       "      <td>5.348204</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129371</th>\n",
       "      <td>72</td>\n",
       "      <td>0.613501</td>\n",
       "      <td>0.109210</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>2.574726</td>\n",
       "      <td>0.012174</td>\n",
       "      <td>0.169081</td>\n",
       "      <td>1.197614</td>\n",
       "      <td>0.235894</td>\n",
       "      <td>0.065669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029722</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>1.056336</td>\n",
       "      <td>8.349836</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77686</th>\n",
       "      <td>654</td>\n",
       "      <td>0.348917</td>\n",
       "      <td>0.075573</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>4.048223</td>\n",
       "      <td>0.026266</td>\n",
       "      <td>0.219966</td>\n",
       "      <td>0.381231</td>\n",
       "      <td>0.051937</td>\n",
       "      <td>0.054336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012389</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.431750</td>\n",
       "      <td>5.694486</td>\n",
       "      <td>0.007268</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.171796</td>\n",
       "      <td>1.194481</td>\n",
       "      <td>-1.250080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110708</th>\n",
       "      <td>875</td>\n",
       "      <td>0.541670</td>\n",
       "      <td>0.469106</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>3.390920</td>\n",
       "      <td>0.101955</td>\n",
       "      <td>2.579604</td>\n",
       "      <td>0.224324</td>\n",
       "      <td>0.020290</td>\n",
       "      <td>0.760739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.473572</td>\n",
       "      <td>0.648063</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.018898</td>\n",
       "      <td>0.624563</td>\n",
       "      <td>-0.776705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77970</th>\n",
       "      <td>683</td>\n",
       "      <td>0.412350</td>\n",
       "      <td>0.106346</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>23.971774</td>\n",
       "      <td>-0.034589</td>\n",
       "      <td>0.334292</td>\n",
       "      <td>1.221020</td>\n",
       "      <td>-0.062910</td>\n",
       "      <td>0.013945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009924</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>0.590305</td>\n",
       "      <td>3.961255</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.197150</td>\n",
       "      <td>1.228235</td>\n",
       "      <td>-1.518445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>527</td>\n",
       "      <td>0.566360</td>\n",
       "      <td>0.404144</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>5.153496</td>\n",
       "      <td>0.190384</td>\n",
       "      <td>1.926307</td>\n",
       "      <td>2.614588</td>\n",
       "      <td>-0.023169</td>\n",
       "      <td>0.373786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006986</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.537003</td>\n",
       "      <td>3.973304</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>1.378815</td>\n",
       "      <td>-1.278062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131463</th>\n",
       "      <td>936</td>\n",
       "      <td>0.502752</td>\n",
       "      <td>0.448166</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>2.224959</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>1.989022</td>\n",
       "      <td>0.229889</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>0.893959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.391692</td>\n",
       "      <td>1.081265</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.061175</td>\n",
       "      <td>1.207845</td>\n",
       "      <td>-2.129311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131464 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age   aliq_at  aliq_mat  ami_126d      at_be    at_gr1     at_me  \\\n",
       "0       132  0.985818  0.059472  0.000026   1.260918  0.651395  0.042021   \n",
       "23522   600  0.610528  0.069305  0.000105   2.318300 -0.088342  0.149204   \n",
       "75824   325       NaN       NaN  0.004628  11.225380  0.119811  4.214064   \n",
       "76014    60  0.616255  0.219590  0.000887   2.971011  0.093083  0.441731   \n",
       "129371   72  0.613501  0.109210  0.001278   2.574726  0.012174  0.169081   \n",
       "...     ...       ...       ...       ...        ...       ...       ...   \n",
       "77686   654  0.348917  0.075573  0.000042   4.048223  0.026266  0.219966   \n",
       "110708  875  0.541670  0.469106  0.000079   3.390920  0.101955  2.579604   \n",
       "77970   683  0.412350  0.106346  0.000052  23.971774 -0.034589  0.334292   \n",
       "9565    527  0.566360  0.404144  0.000205   5.153496  0.190384  1.926307   \n",
       "131463  936  0.502752  0.448166  0.000064   2.224959  0.033296  1.989022   \n",
       "\n",
       "        at_turnover   be_gr1a     be_me  ...  tax_gr1a  turnover_126d  \\\n",
       "0          1.028183  0.310450  0.033325  ...  0.018174       0.003022   \n",
       "23522      0.845524 -0.035351  0.064359  ... -0.013003       0.002484   \n",
       "75824      0.086138  0.003968  0.375405  ...  0.001342       0.003168   \n",
       "76014      1.506417  0.083045  0.148680  ...  0.002257       0.003886   \n",
       "129371     1.197614  0.235894  0.065669  ...  0.029722       0.006013   \n",
       "...             ...       ...       ...  ...       ...            ...   \n",
       "77686      0.381231  0.051937  0.054336  ... -0.012389       0.003985   \n",
       "110708     0.224324  0.020290  0.760739  ...  0.000223       0.012001   \n",
       "77970      1.221020 -0.062910  0.013945  ... -0.009924       0.011881   \n",
       "9565       2.614588 -0.023169  0.373786  ... -0.006986       0.013285   \n",
       "131463     0.229889 -0.000261  0.893959  ...  0.000052       0.007469   \n",
       "\n",
       "        turnover_var_126d    z_score  zero_trades_126d  zero_trades_21d  \\\n",
       "0                0.336775  43.032362          0.004157         0.005002   \n",
       "23522            0.472298  10.113916          0.004944         0.006133   \n",
       "75824            0.729098        NaN          0.003974         0.004473   \n",
       "76014            0.509687   5.348204          0.003278         0.004529   \n",
       "129371           1.056336   8.349836          0.001912         0.002674   \n",
       "...                   ...        ...               ...              ...   \n",
       "77686            0.431750   5.694486          0.007268         0.005775   \n",
       "110708           0.473572   0.648063          0.002548         0.001582   \n",
       "77970            0.590305   3.961255          0.002585         0.001735   \n",
       "9565             0.537003   3.973304          0.002241         0.002721   \n",
       "131463           0.391692   1.081265          0.004487         0.003086   \n",
       "\n",
       "        zero_trades_252d  log_diff  frac_diff      sadf  \n",
       "0               0.003226  0.000000   0.000000  0.000000  \n",
       "23522           0.004822  0.000000   0.000000  0.000000  \n",
       "75824           0.004011  0.000000   0.000000  0.000000  \n",
       "76014           0.003185  0.000000   0.000000  0.000000  \n",
       "129371          0.002260  0.000000   0.000000  0.000000  \n",
       "...                  ...       ...        ...       ...  \n",
       "77686           0.007261  0.171796   1.194481 -1.250080  \n",
       "110708          0.002992  0.018898   0.624563 -0.776705  \n",
       "77970           0.003006  0.197150   1.228235 -1.518445  \n",
       "9565            0.002129  0.039123   1.378815 -1.278062  \n",
       "131463          0.004744  0.061175   1.207845 -2.129311  \n",
       "\n",
       "[131464 rows x 150 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_exret</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>t1</th>\n",
       "      <th>t1_index</th>\n",
       "      <th>weight_attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018070</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.364712</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.018070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23522</th>\n",
       "      <td>0.001539</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.144033</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75824</th>\n",
       "      <td>0.054724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.405740</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.054724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76014</th>\n",
       "      <td>0.009531</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.533961</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.009531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129371</th>\n",
       "      <td>0.389768</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.157432</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.389768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77686</th>\n",
       "      <td>0.065845</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.661575</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0.065845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110708</th>\n",
       "      <td>0.031191</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.186675</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0.031191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77970</th>\n",
       "      <td>-0.009602</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.822283</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0.009602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>0.105924</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973849</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0.105924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131463</th>\n",
       "      <td>0.042407</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.362189</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0.042407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131464 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_exret  target  prediction  probability          t1    t1_index  \\\n",
       "0          0.018070       1         1.0     0.364712  2000-01-31  2000-01-03   \n",
       "23522      0.001539       1        -1.0     0.144033  2000-01-31  2000-01-03   \n",
       "75824      0.054724       1         1.0     0.405740  2000-01-31  2000-01-03   \n",
       "76014      0.009531       1        -1.0     0.533961  2000-01-31  2000-01-03   \n",
       "129371     0.389768       1        -1.0     0.157432  2000-01-31  2000-01-03   \n",
       "...             ...     ...         ...          ...         ...         ...   \n",
       "77686      0.065845       1        -1.0     0.661575  2023-12-29  2023-12-01   \n",
       "110708     0.031191       1         1.0     0.186675  2023-12-29  2023-12-01   \n",
       "77970     -0.009602      -1         1.0     0.822283  2023-12-29  2023-12-01   \n",
       "9565       0.105924       1         1.0     0.973849  2023-12-29  2023-12-01   \n",
       "131463     0.042407       1        -1.0     0.362189  2023-12-29  2023-12-01   \n",
       "\n",
       "        weight_attr  \n",
       "0          0.018070  \n",
       "23522      0.001539  \n",
       "75824      0.054724  \n",
       "76014      0.009531  \n",
       "129371     0.389768  \n",
       "...             ...  \n",
       "77686      0.065845  \n",
       "110708     0.031191  \n",
       "77970      0.009602  \n",
       "9565       0.105924  \n",
       "131463     0.042407  \n",
       "\n",
       "[131464 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>aliq_at</th>\n",
       "      <th>aliq_mat</th>\n",
       "      <th>ami_126d</th>\n",
       "      <th>at_be</th>\n",
       "      <th>at_gr1</th>\n",
       "      <th>at_me</th>\n",
       "      <th>at_turnover</th>\n",
       "      <th>be_gr1a</th>\n",
       "      <th>be_me</th>\n",
       "      <th>...</th>\n",
       "      <th>tax_gr1a</th>\n",
       "      <th>turnover_126d</th>\n",
       "      <th>turnover_var_126d</th>\n",
       "      <th>z_score</th>\n",
       "      <th>zero_trades_126d</th>\n",
       "      <th>zero_trades_21d</th>\n",
       "      <th>zero_trades_252d</th>\n",
       "      <th>log_diff</th>\n",
       "      <th>frac_diff</th>\n",
       "      <th>sadf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_index</th>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2000-01-03</th>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>0.985818</td>\n",
       "      <td>0.059472</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.260918</td>\n",
       "      <td>0.651395</td>\n",
       "      <td>0.042021</td>\n",
       "      <td>1.028183</td>\n",
       "      <td>0.310450</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018174</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.336775</td>\n",
       "      <td>43.032362</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23522</th>\n",
       "      <td>600</td>\n",
       "      <td>0.610528</td>\n",
       "      <td>0.069305</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>2.318300</td>\n",
       "      <td>-0.088342</td>\n",
       "      <td>0.149204</td>\n",
       "      <td>0.845524</td>\n",
       "      <td>-0.035351</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013003</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.472298</td>\n",
       "      <td>10.113916</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75824</th>\n",
       "      <td>325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>11.225380</td>\n",
       "      <td>0.119811</td>\n",
       "      <td>4.214064</td>\n",
       "      <td>0.086138</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.375405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.729098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76014</th>\n",
       "      <td>60</td>\n",
       "      <td>0.616255</td>\n",
       "      <td>0.219590</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>2.971011</td>\n",
       "      <td>0.093083</td>\n",
       "      <td>0.441731</td>\n",
       "      <td>1.506417</td>\n",
       "      <td>0.083045</td>\n",
       "      <td>0.148680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.509687</td>\n",
       "      <td>5.348204</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129371</th>\n",
       "      <td>72</td>\n",
       "      <td>0.613501</td>\n",
       "      <td>0.109210</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>2.574726</td>\n",
       "      <td>0.012174</td>\n",
       "      <td>0.169081</td>\n",
       "      <td>1.197614</td>\n",
       "      <td>0.235894</td>\n",
       "      <td>0.065669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029722</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>1.056336</td>\n",
       "      <td>8.349836</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2023-12-01</th>\n",
       "      <th>77686</th>\n",
       "      <td>654</td>\n",
       "      <td>0.348917</td>\n",
       "      <td>0.075573</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>4.048223</td>\n",
       "      <td>0.026266</td>\n",
       "      <td>0.219966</td>\n",
       "      <td>0.381231</td>\n",
       "      <td>0.051937</td>\n",
       "      <td>0.054336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012389</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.431750</td>\n",
       "      <td>5.694486</td>\n",
       "      <td>0.007268</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.171796</td>\n",
       "      <td>1.194481</td>\n",
       "      <td>-1.250080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110708</th>\n",
       "      <td>875</td>\n",
       "      <td>0.541670</td>\n",
       "      <td>0.469106</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>3.390920</td>\n",
       "      <td>0.101955</td>\n",
       "      <td>2.579604</td>\n",
       "      <td>0.224324</td>\n",
       "      <td>0.020290</td>\n",
       "      <td>0.760739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.473572</td>\n",
       "      <td>0.648063</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.018898</td>\n",
       "      <td>0.624563</td>\n",
       "      <td>-0.776705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77970</th>\n",
       "      <td>683</td>\n",
       "      <td>0.412350</td>\n",
       "      <td>0.106346</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>23.971774</td>\n",
       "      <td>-0.034589</td>\n",
       "      <td>0.334292</td>\n",
       "      <td>1.221020</td>\n",
       "      <td>-0.062910</td>\n",
       "      <td>0.013945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009924</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>0.590305</td>\n",
       "      <td>3.961255</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.197150</td>\n",
       "      <td>1.228235</td>\n",
       "      <td>-1.518445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>527</td>\n",
       "      <td>0.566360</td>\n",
       "      <td>0.404144</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>5.153496</td>\n",
       "      <td>0.190384</td>\n",
       "      <td>1.926307</td>\n",
       "      <td>2.614588</td>\n",
       "      <td>-0.023169</td>\n",
       "      <td>0.373786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006986</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.537003</td>\n",
       "      <td>3.973304</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>1.378815</td>\n",
       "      <td>-1.278062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131463</th>\n",
       "      <td>936</td>\n",
       "      <td>0.502752</td>\n",
       "      <td>0.448166</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>2.224959</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>1.989022</td>\n",
       "      <td>0.229889</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>0.893959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.391692</td>\n",
       "      <td>1.081265</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.061175</td>\n",
       "      <td>1.207845</td>\n",
       "      <td>-2.129311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131464 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   age   aliq_at  aliq_mat  ami_126d      at_be    at_gr1  \\\n",
       "t1_index   index                                                            \n",
       "2000-01-03 0       132  0.985818  0.059472  0.000026   1.260918  0.651395   \n",
       "           23522   600  0.610528  0.069305  0.000105   2.318300 -0.088342   \n",
       "           75824   325       NaN       NaN  0.004628  11.225380  0.119811   \n",
       "           76014    60  0.616255  0.219590  0.000887   2.971011  0.093083   \n",
       "           129371   72  0.613501  0.109210  0.001278   2.574726  0.012174   \n",
       "...                ...       ...       ...       ...        ...       ...   \n",
       "2023-12-01 77686   654  0.348917  0.075573  0.000042   4.048223  0.026266   \n",
       "           110708  875  0.541670  0.469106  0.000079   3.390920  0.101955   \n",
       "           77970   683  0.412350  0.106346  0.000052  23.971774 -0.034589   \n",
       "           9565    527  0.566360  0.404144  0.000205   5.153496  0.190384   \n",
       "           131463  936  0.502752  0.448166  0.000064   2.224959  0.033296   \n",
       "\n",
       "                      at_me  at_turnover   be_gr1a     be_me  ...  tax_gr1a  \\\n",
       "t1_index   index                                              ...             \n",
       "2000-01-03 0       0.042021     1.028183  0.310450  0.033325  ...  0.018174   \n",
       "           23522   0.149204     0.845524 -0.035351  0.064359  ... -0.013003   \n",
       "           75824   4.214064     0.086138  0.003968  0.375405  ...  0.001342   \n",
       "           76014   0.441731     1.506417  0.083045  0.148680  ...  0.002257   \n",
       "           129371  0.169081     1.197614  0.235894  0.065669  ...  0.029722   \n",
       "...                     ...          ...       ...       ...  ...       ...   \n",
       "2023-12-01 77686   0.219966     0.381231  0.051937  0.054336  ... -0.012389   \n",
       "           110708  2.579604     0.224324  0.020290  0.760739  ...  0.000223   \n",
       "           77970   0.334292     1.221020 -0.062910  0.013945  ... -0.009924   \n",
       "           9565    1.926307     2.614588 -0.023169  0.373786  ... -0.006986   \n",
       "           131463  1.989022     0.229889 -0.000261  0.893959  ...  0.000052   \n",
       "\n",
       "                   turnover_126d  turnover_var_126d    z_score  \\\n",
       "t1_index   index                                                 \n",
       "2000-01-03 0            0.003022           0.336775  43.032362   \n",
       "           23522        0.002484           0.472298  10.113916   \n",
       "           75824        0.003168           0.729098        NaN   \n",
       "           76014        0.003886           0.509687   5.348204   \n",
       "           129371       0.006013           1.056336   8.349836   \n",
       "...                          ...                ...        ...   \n",
       "2023-12-01 77686        0.003985           0.431750   5.694486   \n",
       "           110708       0.012001           0.473572   0.648063   \n",
       "           77970        0.011881           0.590305   3.961255   \n",
       "           9565         0.013285           0.537003   3.973304   \n",
       "           131463       0.007469           0.391692   1.081265   \n",
       "\n",
       "                   zero_trades_126d  zero_trades_21d  zero_trades_252d  \\\n",
       "t1_index   index                                                         \n",
       "2000-01-03 0               0.004157         0.005002          0.003226   \n",
       "           23522           0.004944         0.006133          0.004822   \n",
       "           75824           0.003974         0.004473          0.004011   \n",
       "           76014           0.003278         0.004529          0.003185   \n",
       "           129371          0.001912         0.002674          0.002260   \n",
       "...                             ...              ...               ...   \n",
       "2023-12-01 77686           0.007268         0.005775          0.007261   \n",
       "           110708          0.002548         0.001582          0.002992   \n",
       "           77970           0.002585         0.001735          0.003006   \n",
       "           9565            0.002241         0.002721          0.002129   \n",
       "           131463          0.004487         0.003086          0.004744   \n",
       "\n",
       "                   log_diff  frac_diff      sadf  \n",
       "t1_index   index                                  \n",
       "2000-01-03 0       0.000000   0.000000  0.000000  \n",
       "           23522   0.000000   0.000000  0.000000  \n",
       "           75824   0.000000   0.000000  0.000000  \n",
       "           76014   0.000000   0.000000  0.000000  \n",
       "           129371  0.000000   0.000000  0.000000  \n",
       "...                     ...        ...       ...  \n",
       "2023-12-01 77686   0.171796   1.194481 -1.250080  \n",
       "           110708  0.018898   0.624563 -0.776705  \n",
       "           77970   0.197150   1.228235 -1.518445  \n",
       "           9565    0.039123   1.378815 -1.278062  \n",
       "           131463  0.061175   1.207845 -2.129311  \n",
       "\n",
       "[131464 rows x 150 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['t1_index'] = Y['t1_index']\n",
    "X.reset_index(inplace=True)\n",
    "X.set_index(['t1_index', 'index'], inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X contains the feautes given and ADDED BY US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>stock_exret</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>t1</th>\n",
       "      <th>weight_attr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_index</th>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2000-01-03</th>\n",
       "      <th>0</th>\n",
       "      <td>0.018070</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.364712</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>0.018070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23522</th>\n",
       "      <td>0.001539</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.144033</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75824</th>\n",
       "      <td>0.054724</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.405740</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>0.054724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76014</th>\n",
       "      <td>0.009531</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.533961</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>0.009531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129371</th>\n",
       "      <td>0.389768</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.157432</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>0.389768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2023-12-01</th>\n",
       "      <th>77686</th>\n",
       "      <td>0.065845</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.661575</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.065845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110708</th>\n",
       "      <td>0.031191</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.186675</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.031191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77970</th>\n",
       "      <td>-0.009602</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.822283</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.009602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>0.105924</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973849</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.105924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131463</th>\n",
       "      <td>0.042407</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.362189</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.042407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131464 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   stock_exret  target  prediction  probability          t1  \\\n",
       "t1_index   index                                                              \n",
       "2000-01-03 0          0.018070       1         1.0     0.364712  2000-01-31   \n",
       "           23522      0.001539       1        -1.0     0.144033  2000-01-31   \n",
       "           75824      0.054724       1         1.0     0.405740  2000-01-31   \n",
       "           76014      0.009531       1        -1.0     0.533961  2000-01-31   \n",
       "           129371     0.389768       1        -1.0     0.157432  2000-01-31   \n",
       "...                        ...     ...         ...          ...         ...   \n",
       "2023-12-01 77686      0.065845       1        -1.0     0.661575  2023-12-29   \n",
       "           110708     0.031191       1         1.0     0.186675  2023-12-29   \n",
       "           77970     -0.009602      -1         1.0     0.822283  2023-12-29   \n",
       "           9565       0.105924       1         1.0     0.973849  2023-12-29   \n",
       "           131463     0.042407       1        -1.0     0.362189  2023-12-29   \n",
       "\n",
       "                   weight_attr  \n",
       "t1_index   index                \n",
       "2000-01-03 0          0.018070  \n",
       "           23522      0.001539  \n",
       "           75824      0.054724  \n",
       "           76014      0.009531  \n",
       "           129371     0.389768  \n",
       "...                        ...  \n",
       "2023-12-01 77686      0.065845  \n",
       "           110708     0.031191  \n",
       "           77970      0.009602  \n",
       "           9565       0.105924  \n",
       "           131463     0.042407  \n",
       "\n",
       "[131464 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.reset_index()\n",
    "Y.set_index(['t1_index', 'index'], inplace=True)\n",
    "Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currently, in $Y$,\n",
    "\n",
    "*prediction* and *probability* are randomly generated, those are the columns\n",
    "we must fill for the investment perdiod (2008-) we our true probabilities and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WE WANT TO PREDICT TARGET, which is simply the sign of stock_exret\n",
    "\n",
    "## Weight_attr IS SO IMPORANT, PLEASE DON'T IGNORE \n",
    "\n",
    "As Uday did in feature importance, this weight_attr must be rescaled for the \n",
    "training period. Right now, it is scaled for the whole dataset, you must reajust\n",
    "it for the training period such that the suym of the weight = Size of the training period\n",
    "\n",
    "*= X_train.shape[0]/X_train['weight_attr'].sum()\n",
    "\n",
    "Uday did it I believe\n",
    "\n",
    "Refer to section 4.6 if you have any doubts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "\n",
    "# Define base RandomForestClassifier (without setting n_estimators because we'll search for it)\n",
    "base_rf = RandomForestClassifier(\n",
    "    criterion=\"entropy\",  # use entropy for information gain\n",
    "    bootstrap=False,  # no bootstrap\n",
    "    class_weight=\"balanced_subsample\"  # handle class imbalance\n",
    ")\n",
    "\n",
    "# Define the parameter search space for BayesSearchCV\n",
    "param_space = {\n",
    "    'estimator__n_estimators': Integer(10, 100),  # number of trees in RF\n",
    "    'estimator__max_depth': Integer(5, 50),  # depth of each tree\n",
    "    'estimator__min_samples_split': Integer(2, 10),  # minimum samples required to split a node\n",
    "    'estimator__min_samples_leaf': Integer(1, 5),  # minimum samples required in a leaf node\n",
    "    'estimator__max_features': Categorical([\"auto\", \"sqrt\", \"log2\"]),  # feature selection for RF\n",
    "    'n_estimators': Integer(10, 500),  # number of bagging classifiers\n",
    "    'max_samples': Real(0.1, 1.0),  # fraction of samples for each bagging classifier\n",
    "    'max_features': Real(0.1, 1.0),  # fraction of features for each base estimator\n",
    "}\n",
    "\n",
    "# Initialize BaggingClassifier with RandomForestClassifier as the base estimator\n",
    "bagging_clf = BaggingClassifier(\n",
    "    estimator=base_rf,\n",
    "    oob_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Set up BayesSearchCV with BaggingClassifier and the parameter search space\n",
    "optimizer = BayesSearchCV(\n",
    "    bagging_clf,\n",
    "    param_space,\n",
    "    n_iter=50,  # number of iterations for hyperparameter search\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model with training data\n",
    "optimizer.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_model = optimizer.best_estimator_\n",
    "print(f\"Best parameters found: {optimizer.best_params_}\")\n",
    "\n",
    "# Make predictions using the optimized model\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "The method is explained in the FIAM instructions, please refer to pages\\\n",
    "6 and 7, sections **Performance evaluation** AND **Training Procedures**\\\n",
    "(especially training procedures)\n",
    "\n",
    "As they mention it in the doc, they provided an implementation of the method,\n",
    "\n",
    "penalized_linear_hackathon.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Start: 2000-01-01 00:00:00, Train End: 2008-01-01 00:00:00, Val Start: 2008-01-01 00:00:00, Val End: 2010-01-01 00:00:00, Test Start: 2010-01-01 00:00:00, Test End: 2011-01-01 00:00:00\n",
      "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n",
      "[CV] END estimator__max_depth=6, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=7, estimator__n_estimators=815, max_features=0.10077876584101433, max_samples=1.0922115592912176, n_estimators=42; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r_/jx86zm6j6jz70fwxkrhjzcfw0000gn/T/ipykernel_32806/1966811691.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_train['weight_attr'] *= Y_train.shape[0] / Y_train['weight_attr'].sum()\n",
      "/var/folders/r_/jx86zm6j6jz70fwxkrhjzcfw0000gn/T/ipykernel_32806/1966811691.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_validate['weight_attr'] *= Y_validate.shape[0] / Y_validate['weight_attr'].sum()\n",
      "/var/folders/r_/jx86zm6j6jz70fwxkrhjzcfw0000gn/T/ipykernel_32806/1966811691.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y_test['weight_attr'] *= Y_test.shape[0] / Y_test['weight_attr'].sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time=  43.8s\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import PredefinedSplit, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Initialize the starting date, counter, and output data\n",
    "stock_vars = ['ret_1_0', 'prc_highprc_252d', 'seas_1_1na', 'rmax5_21d']  # List of features\n",
    "tgt_var = 'target'  # Target variable\n",
    "\n",
    "starting = pd.to_datetime(\"20000101\", format=\"%Y%m%d\")\n",
    "counter = 0\n",
    "pred_out = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Ensure that the indices of X and Y are MultiIndex with datetime as the first level\n",
    "X.index = pd.MultiIndex.from_tuples(\n",
    "    [(pd.to_datetime(t1_index), other_index) for t1_index, other_index in X.index]\n",
    ")\n",
    "Y.index = pd.MultiIndex.from_tuples(\n",
    "    [(pd.to_datetime(t1_index), other_index) for t1_index, other_index in Y.index]\n",
    ")\n",
    "\n",
    "# Estimation with expanding window\n",
    "while (starting + pd.DateOffset(years=11 + counter)) <= pd.to_datetime(\"20240101\", format=\"%Y%m%d\"):\n",
    "    # For testing purposes, limit the number of iterations\n",
    "    # Remove or adjust this condition as needed\n",
    "    if counter == 1:\n",
    "        break\n",
    "\n",
    "    cutoff = [\n",
    "        starting,\n",
    "        starting + pd.DateOffset(years=8 + counter),  # Training set end date\n",
    "        starting + pd.DateOffset(years=10 + counter),  # Validation set end date\n",
    "        starting + pd.DateOffset(years=11 + counter),  # Test set end date\n",
    "    ]\n",
    "\n",
    "    print(f\"Train Start: {cutoff[0]}, Train End: {cutoff[1]}, Val Start: {cutoff[1]}, Val End: {cutoff[2]}, Test Start: {cutoff[2]}, Test End: {cutoff[3]}\")\n",
    "\n",
    "    # Cut the sample into training, validation, and testing sets\n",
    "    X_train = X[(X.index.get_level_values(0) >= cutoff[0]) & (X.index.get_level_values(0) < cutoff[1])]\n",
    "    X_validate = X[(X.index.get_level_values(0) >= cutoff[1]) & (X.index.get_level_values(0) < cutoff[2])]\n",
    "    X_test = X[(X.index.get_level_values(0) >= cutoff[2]) & (X.index.get_level_values(0) < cutoff[3])]\n",
    "\n",
    "    Y_train = Y[(Y.index.get_level_values(0) >= cutoff[0]) & (Y.index.get_level_values(0) < cutoff[1])]\n",
    "    Y_validate = Y[(Y.index.get_level_values(0) >= cutoff[1]) & (Y.index.get_level_values(0) < cutoff[2])]\n",
    "    Y_test = Y[(Y.index.get_level_values(0) >= cutoff[2]) & (Y.index.get_level_values(0) < cutoff[3])]\n",
    "\n",
    "    # Adjust sample weights\n",
    "    Y_train['weight_attr'] *= Y_train.shape[0] / Y_train['weight_attr'].sum()\n",
    "    Y_validate['weight_attr'] *= Y_validate.shape[0] / Y_validate['weight_attr'].sum()\n",
    "    Y_test['weight_attr'] *= Y_test.shape[0] / Y_test['weight_attr'].sum()\n",
    "\n",
    "    # Get feature matrices\n",
    "    X_train_vals = X_train[stock_vars].values\n",
    "    X_validate_vals = X_validate[stock_vars].values\n",
    "    X_test_vals = X_test[stock_vars].values\n",
    "\n",
    "    # Combine training and validation sets\n",
    "    X_train_val = np.vstack([X_train_vals, X_validate_vals])\n",
    "    Y_train_val = pd.concat([Y_train, Y_validate])\n",
    "\n",
    "    # Create test_fold for PredefinedSplit\n",
    "    test_fold = np.concatenate([\n",
    "        np.full(len(X_train_vals), -1),  # Training set indices\n",
    "        np.zeros(len(X_validate_vals))   # Validation set indices\n",
    "    ])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "\n",
    "    # Define base estimator\n",
    "    base_rf = RandomForestClassifier(\n",
    "        criterion=\"entropy\",\n",
    "        bootstrap=False,\n",
    "        class_weight=\"balanced_subsample\"\n",
    "    )\n",
    "\n",
    "    # Define bagging classifier\n",
    "    bagging_clf = BaggingClassifier(\n",
    "        estimator=base_rf,\n",
    "        oob_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Define parameter space for hyperparameter optimization\n",
    "    param_distributions = {\n",
    "    'estimator__n_estimators': randint(10, 1000),\n",
    "    'estimator__max_depth': randint(5, 50),\n",
    "    'estimator__min_samples_split': randint(2, 10),\n",
    "    'estimator__min_samples_leaf': randint(1, 5),\n",
    "    'estimator__max_features': ['sqrt', 'log2'],  # Categorical choices for RandomForestClassifier\n",
    "    'n_estimators': randint(10, 100),  # Number of bagging estimators\n",
    "    'max_samples': uniform(0.1, 1.0),  # Fraction of samples for each bagging classifier\n",
    "    'max_features': uniform(0.1, 1.0)  # Fraction of features for each bagging classifier (must be a float)\n",
    "    }\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = RandomizedSearchCV(\n",
    "    bagging_clf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,  # Number of iterations for hyperparameter search\n",
    "    cv=ps,      # Use predefined split\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    "    )   \n",
    "\n",
    "    # Fit optimizer with sample weights\n",
    "    optimizer.fit(\n",
    "        X_train_val,\n",
    "        Y_train_val[tgt_var].values,\n",
    "        **{'sample_weight': Y_train_val['weight_attr'].values}\n",
    "    )\n",
    "\n",
    "    # Retrieve the best estimator\n",
    "    best_estimator = optimizer.best_estimator_\n",
    "\n",
    "    # Retrain best_estimator on combined training and validation set\n",
    "    best_estimator.fit(\n",
    "        X_train_val,\n",
    "        Y_train_val[tgt_var].values,\n",
    "        sample_weight=Y_train_val['weight_attr'].values\n",
    "    )\n",
    "\n",
    "    # Predict on test set\n",
    "    prob = best_estimator.predict_proba(X_test_vals)\n",
    "    score_ = -log_loss(Y_test[tgt_var].values, prob, sample_weight=Y_test[\"weight_attr\"].values, labels=best_estimator.classes_)\n",
    "    print(\"Log Loss on Test Set:\", score_)\n",
    "\n",
    "    # Store predictions in Y_test\n",
    "    Y_test['prediction'] = best_estimator.predict(X_test_vals)\n",
    "    Y_test['probability'] = prob.max(axis=1)\n",
    "\n",
    "    print(\"Predictions on Test Set:\")\n",
    "    print(Y_test['prediction'])\n",
    "    print(\"Probabilities on Test Set:\")\n",
    "    print(Y_test['probability'])\n",
    "    print(\"Prediction Probabilities:\")\n",
    "    print(prob)\n",
    "\n",
    "    # Optionally, store predictions in pred_out DataFrame\n",
    "    # pred_out = pred_out.append(Y_test[['prediction', 'probability']])\n",
    "\n",
    "    # Increment counter\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use one of the following. For clarification, refer to **6.4**\n",
    "\n",
    "I believe clf2 is the best one\n",
    "\n",
    "### This is from my deprado repo, *ch_06.ipynb*\n",
    "\n",
    "```python\n",
    "# Libraries\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dataset\n",
    "X, Y = f_ch8.getTestData(n_features=40, n_informative=3, n_redundant=30, n_samples=10000)\n",
    "Y = Y[\"bin\"]\n",
    "\n",
    "# usual RF\n",
    "clf0 = RandomForestClassifier(\n",
    "    n_estimators=1_000,  # 1_000 trees\n",
    "    class_weight=\"balanced_subsample\",  # prevent minority class from being ignored\n",
    "    criterion=\"entropy\"  # information gain\n",
    ")\n",
    "\n",
    "# Ensemble of estimators with base estimator as a decision tree\n",
    "clf1 = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",  # information gain\n",
    "    max_features=\"sqrt\",  # sqrt(n_features) to force diversity among trees\n",
    "    class_weight=\"balanced\"  # prevent minority class from being ignored\n",
    ")\n",
    "clf1 = BaggingClassifier(\n",
    "    estimator=clf1,  # base estimator\n",
    "    n_estimators=1_000,  # 1_000 trees\n",
    "    max_samples=0.6,  # average uniqueness\n",
    "    max_features=1.0  # all features for bagging\n",
    ")\n",
    "\n",
    "# Bagging classifier on RF where max_samples is set to average uniqueness\n",
    "clf2 = RandomForestClassifier(\n",
    "    n_estimators=1,  # 1 tree\n",
    "    criterion=\"entropy\",  # information gain\n",
    "    bootstrap=False,  # no bootstrap\n",
    "    class_weight=\"balanced_subsample\"  # prevent minority class from being ignored\n",
    ")\n",
    "\n",
    "clf2 = BaggingClassifier(\n",
    "    estimator=clf2,  # base estimator\n",
    "    n_estimators=1_000,  # 1_000 trees\n",
    "    max_samples=1.0,  # average uniqueness\n",
    "    max_features=1.0  # all features for bagging\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning\n",
    "\n",
    "### Here is why the weights are so important\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to *9.4* , you can use accuracy, but negative log likelihood is suggested,\\\n",
    "since it takes into account the probability of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hyperparaemtes, i believe you guys can figure out better than me what\n",
    "to set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please be aware of the bugs mentioned in\n",
    "\n",
    "- 7.5 BUGS IN SKLEARN’S CROSS-VALIDATION\n",
    "- SNIPPET 9.2 AN ENHANCED PIPELINE CLASS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I'M AVAILABLE ALL DAY, PLEASE ASK ME ANYTHING, LET'S GOOOOO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financial_math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
