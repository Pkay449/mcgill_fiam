{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import log_loss,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **MUST RUN 01-Data_Preprocessing/01-preprocessing_code.py AND 02-Feature_Engineering/01-fe_code.py BEFORE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have the following dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load objects/X_DATASET.pkl and objects/Y_DATASET.pkl\n",
    "X = pd.read_pickle('../objects/X_DATASET.pkl')\n",
    "Y = pd.read_pickle('../objects/Y_DATASET.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>aliq_at</th>\n",
       "      <th>aliq_mat</th>\n",
       "      <th>ami_126d</th>\n",
       "      <th>at_be</th>\n",
       "      <th>at_gr1</th>\n",
       "      <th>at_me</th>\n",
       "      <th>at_turnover</th>\n",
       "      <th>be_gr1a</th>\n",
       "      <th>be_me</th>\n",
       "      <th>...</th>\n",
       "      <th>taccruals_at</th>\n",
       "      <th>taccruals_ni</th>\n",
       "      <th>tangibility</th>\n",
       "      <th>tax_gr1a</th>\n",
       "      <th>turnover_126d</th>\n",
       "      <th>turnover_var_126d</th>\n",
       "      <th>z_score</th>\n",
       "      <th>zero_trades_126d</th>\n",
       "      <th>zero_trades_21d</th>\n",
       "      <th>zero_trades_252d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>0.985818</td>\n",
       "      <td>0.059472</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.260918</td>\n",
       "      <td>0.651395</td>\n",
       "      <td>0.042021</td>\n",
       "      <td>1.028183</td>\n",
       "      <td>0.310450</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132759</td>\n",
       "      <td>0.932668</td>\n",
       "      <td>0.287709</td>\n",
       "      <td>0.018174</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.336775</td>\n",
       "      <td>43.032362</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.003226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>784</td>\n",
       "      <td>0.636280</td>\n",
       "      <td>0.419246</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>3.002603</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.982853</td>\n",
       "      <td>1.561359</td>\n",
       "      <td>-0.007330</td>\n",
       "      <td>0.327334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070334</td>\n",
       "      <td>-1.350656</td>\n",
       "      <td>0.571700</td>\n",
       "      <td>0.030609</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.451566</td>\n",
       "      <td>3.381417</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79192</th>\n",
       "      <td>156</td>\n",
       "      <td>1.078982</td>\n",
       "      <td>0.497954</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>12.300384</td>\n",
       "      <td>0.289454</td>\n",
       "      <td>0.750931</td>\n",
       "      <td>0.212139</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>0.061049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011451</td>\n",
       "      <td>-0.503262</td>\n",
       "      <td>0.858820</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>0.404042</td>\n",
       "      <td>1.087062</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.001720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79017</th>\n",
       "      <td>96</td>\n",
       "      <td>0.766219</td>\n",
       "      <td>0.152166</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>1.311442</td>\n",
       "      <td>0.022729</td>\n",
       "      <td>0.131301</td>\n",
       "      <td>0.662498</td>\n",
       "      <td>0.058250</td>\n",
       "      <td>0.100119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170568</td>\n",
       "      <td>-11.313364</td>\n",
       "      <td>0.751451</td>\n",
       "      <td>-0.003988</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>1.475238</td>\n",
       "      <td>9.327025</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.001469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136801</th>\n",
       "      <td>444</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>21.847603</td>\n",
       "      <td>0.141701</td>\n",
       "      <td>4.562675</td>\n",
       "      <td>0.090603</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.208841</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>1.192832</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.004025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142960</th>\n",
       "      <td>875</td>\n",
       "      <td>0.494857</td>\n",
       "      <td>0.258809</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>2.561048</td>\n",
       "      <td>-0.019929</td>\n",
       "      <td>0.599322</td>\n",
       "      <td>0.790637</td>\n",
       "      <td>0.076776</td>\n",
       "      <td>0.234014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007516</td>\n",
       "      <td>-0.074240</td>\n",
       "      <td>0.615093</td>\n",
       "      <td>0.010144</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>1.452597</td>\n",
       "      <td>2.313842</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.004865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164883</th>\n",
       "      <td>335</td>\n",
       "      <td>0.440289</td>\n",
       "      <td>0.204966</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.369123</td>\n",
       "      <td>0.041082</td>\n",
       "      <td>0.509132</td>\n",
       "      <td>1.101150</td>\n",
       "      <td>0.053765</td>\n",
       "      <td>0.371868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040519</td>\n",
       "      <td>-0.331965</td>\n",
       "      <td>0.445832</td>\n",
       "      <td>-0.002505</td>\n",
       "      <td>0.006820</td>\n",
       "      <td>0.484558</td>\n",
       "      <td>6.825448</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>0.004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56626</th>\n",
       "      <td>467</td>\n",
       "      <td>0.456242</td>\n",
       "      <td>0.073563</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>7.338437</td>\n",
       "      <td>0.106965</td>\n",
       "      <td>0.194904</td>\n",
       "      <td>0.601361</td>\n",
       "      <td>0.050950</td>\n",
       "      <td>0.026559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077962</td>\n",
       "      <td>-0.812357</td>\n",
       "      <td>0.310944</td>\n",
       "      <td>-0.004359</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.423431</td>\n",
       "      <td>3.953374</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.005337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103667</th>\n",
       "      <td>347</td>\n",
       "      <td>0.232903</td>\n",
       "      <td>0.142937</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>2.143037</td>\n",
       "      <td>-0.028275</td>\n",
       "      <td>0.774278</td>\n",
       "      <td>1.205285</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>0.361299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020596</td>\n",
       "      <td>0.472952</td>\n",
       "      <td>0.235576</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>0.504602</td>\n",
       "      <td>3.420703</td>\n",
       "      <td>0.006556</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>0.006052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172784</th>\n",
       "      <td>936</td>\n",
       "      <td>0.502752</td>\n",
       "      <td>0.448166</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>2.224959</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>1.989022</td>\n",
       "      <td>0.229889</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>0.893959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053687</td>\n",
       "      <td>-2.701708</td>\n",
       "      <td>0.587483</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.391692</td>\n",
       "      <td>1.081265</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172785 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age         aliq_at        aliq_mat  ami_126d      at_be    at_gr1  \\\n",
       "0       132        0.985818        0.059472  0.000026   1.260918  0.651395   \n",
       "2781    784        0.636280        0.419246  0.000106   3.002603  0.003136   \n",
       "79192   156        1.078982        0.497954  0.000215  12.300384  0.289454   \n",
       "79017    96        0.766219        0.152166  0.012623   1.311442  0.022729   \n",
       "136801  444  1000000.000000  1000000.000000  0.000583  21.847603  0.141701   \n",
       "...     ...             ...             ...       ...        ...       ...   \n",
       "142960  875        0.494857        0.258809  0.000051   2.561048 -0.019929   \n",
       "164883  335        0.440289        0.204966  0.000043   1.369123  0.041082   \n",
       "56626   467        0.456242        0.073563  0.000047   7.338437  0.106965   \n",
       "103667  347        0.232903        0.142937  0.000458   2.143037 -0.028275   \n",
       "172784  936        0.502752        0.448166  0.000064   2.224959  0.033296   \n",
       "\n",
       "           at_me  at_turnover   be_gr1a     be_me  ...    taccruals_at  \\\n",
       "0       0.042021     1.028183  0.310450  0.033325  ...        0.132759   \n",
       "2781    0.982853     1.561359 -0.007330  0.327334  ...       -0.070334   \n",
       "79192   0.750931     0.212139  0.029724  0.061049  ...       -0.011451   \n",
       "79017   0.131301     0.662498  0.058250  0.100119  ...       -0.170568   \n",
       "136801  4.562675     0.090603  0.005307  0.208841  ...  1000000.000000   \n",
       "...          ...          ...       ...       ...  ...             ...   \n",
       "142960  0.599322     0.790637  0.076776  0.234014  ...       -0.007516   \n",
       "164883  0.509132     1.101150  0.053765  0.371868  ...       -0.040519   \n",
       "56626   0.194904     0.601361  0.050950  0.026559  ...       -0.077962   \n",
       "103667  0.774278     1.205285  0.030875  0.361299  ...        0.020596   \n",
       "172784  1.989022     0.229889 -0.000261  0.893959  ...       -0.053687   \n",
       "\n",
       "          taccruals_ni     tangibility  tax_gr1a  turnover_126d  \\\n",
       "0             0.932668        0.287709  0.018174       0.003022   \n",
       "2781         -1.350656        0.571700  0.030609       0.003256   \n",
       "79192        -0.503262        0.858820  0.007016       0.005098   \n",
       "79017       -11.313364        0.751451 -0.003988       0.007496   \n",
       "136801  1000000.000000  1000000.000000  0.000656       0.003407   \n",
       "...                ...             ...       ...            ...   \n",
       "142960       -0.074240        0.615093  0.010144       0.008145   \n",
       "164883       -0.331965        0.445832 -0.002505       0.006820   \n",
       "56626        -0.812357        0.310944 -0.004359       0.006439   \n",
       "103667        0.472952        0.235576  0.002153       0.004803   \n",
       "172784       -2.701708        0.587483  0.000052       0.007469   \n",
       "\n",
       "        turnover_var_126d         z_score  zero_trades_126d  zero_trades_21d  \\\n",
       "0                0.336775       43.032362          0.004157         0.005002   \n",
       "2781             0.451566        3.381417          0.003881         0.003926   \n",
       "79192            0.404042        1.087062          0.002407         0.003124   \n",
       "79017            1.475238        9.327025          0.001392         0.000767   \n",
       "136801           1.192832  1000000.000000          0.003737         0.005589   \n",
       "...                   ...             ...               ...              ...   \n",
       "142960           1.452597        2.313842          0.004100         0.005428   \n",
       "164883           0.484558        6.825448          0.004906         0.004621   \n",
       "56626            0.423431        3.953374          0.005186         0.004429   \n",
       "103667           0.504602        3.420703          0.006556         0.005650   \n",
       "172784           0.391692        1.081265          0.004487         0.003086   \n",
       "\n",
       "        zero_trades_252d  \n",
       "0               0.003226  \n",
       "2781            0.003549  \n",
       "79192           0.001720  \n",
       "79017           0.001469  \n",
       "136801          0.004025  \n",
       "...                  ...  \n",
       "142960          0.004865  \n",
       "164883          0.004572  \n",
       "56626           0.005337  \n",
       "103667          0.006052  \n",
       "172784          0.004744  \n",
       "\n",
       "[172785 rows x 147 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_exret</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>t1</th>\n",
       "      <th>t1_index</th>\n",
       "      <th>weight_attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018070</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133210</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.018070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>0.069806</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.602130</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.069806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79192</th>\n",
       "      <td>-0.066192</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.484446</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.066192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79017</th>\n",
       "      <td>0.825067</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.881480</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.825067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136801</th>\n",
       "      <td>0.093419</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.093419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142960</th>\n",
       "      <td>0.015598</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.281077</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0.015598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164883</th>\n",
       "      <td>0.068874</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.664075</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0.068874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56626</th>\n",
       "      <td>0.110382</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217701</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0.110382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103667</th>\n",
       "      <td>0.000132</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770597</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172784</th>\n",
       "      <td>0.042407</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936564</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0.042407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172785 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_exret  target  prediction  probability          t1    t1_index  \\\n",
       "0          0.018070       1         1.0     0.133210  2000-01-31  2000-01-03   \n",
       "2781       0.069806       1        -1.0     0.602130  2000-01-31  2000-01-03   \n",
       "79192     -0.066192      -1        -1.0     0.484446  2000-01-31  2000-01-03   \n",
       "79017      0.825067       1        -1.0     0.881480  2000-01-31  2000-01-03   \n",
       "136801     0.093419       1         1.0     0.819652  2000-01-31  2000-01-03   \n",
       "...             ...     ...         ...          ...         ...         ...   \n",
       "142960     0.015598       1        -1.0     0.281077  2023-12-29  2023-12-01   \n",
       "164883     0.068874       1         1.0     0.664075  2023-12-29  2023-12-01   \n",
       "56626      0.110382       1         1.0     0.217701  2023-12-29  2023-12-01   \n",
       "103667     0.000132       1         1.0     0.770597  2023-12-29  2023-12-01   \n",
       "172784     0.042407       1         1.0     0.936564  2023-12-29  2023-12-01   \n",
       "\n",
       "        weight_attr  \n",
       "0          0.018070  \n",
       "2781       0.069806  \n",
       "79192      0.066192  \n",
       "79017      0.825067  \n",
       "136801     0.093419  \n",
       "...             ...  \n",
       "142960     0.015598  \n",
       "164883     0.068874  \n",
       "56626      0.110382  \n",
       "103667     0.000132  \n",
       "172784     0.042407  \n",
       "\n",
       "[172785 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>aliq_at</th>\n",
       "      <th>aliq_mat</th>\n",
       "      <th>ami_126d</th>\n",
       "      <th>at_be</th>\n",
       "      <th>at_gr1</th>\n",
       "      <th>at_me</th>\n",
       "      <th>at_turnover</th>\n",
       "      <th>be_gr1a</th>\n",
       "      <th>be_me</th>\n",
       "      <th>...</th>\n",
       "      <th>taccruals_at</th>\n",
       "      <th>taccruals_ni</th>\n",
       "      <th>tangibility</th>\n",
       "      <th>tax_gr1a</th>\n",
       "      <th>turnover_126d</th>\n",
       "      <th>turnover_var_126d</th>\n",
       "      <th>z_score</th>\n",
       "      <th>zero_trades_126d</th>\n",
       "      <th>zero_trades_21d</th>\n",
       "      <th>zero_trades_252d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_index</th>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2000-01-03</th>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>0.985818</td>\n",
       "      <td>0.059472</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>1.260918</td>\n",
       "      <td>0.651395</td>\n",
       "      <td>0.042021</td>\n",
       "      <td>1.028183</td>\n",
       "      <td>0.310450</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132759</td>\n",
       "      <td>0.932668</td>\n",
       "      <td>0.287709</td>\n",
       "      <td>0.018174</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.336775</td>\n",
       "      <td>43.032362</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>0.003226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>784</td>\n",
       "      <td>0.636280</td>\n",
       "      <td>0.419246</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>3.002603</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.982853</td>\n",
       "      <td>1.561359</td>\n",
       "      <td>-0.007330</td>\n",
       "      <td>0.327334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070334</td>\n",
       "      <td>-1.350656</td>\n",
       "      <td>0.571700</td>\n",
       "      <td>0.030609</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.451566</td>\n",
       "      <td>3.381417</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79192</th>\n",
       "      <td>156</td>\n",
       "      <td>1.078982</td>\n",
       "      <td>0.497954</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>12.300384</td>\n",
       "      <td>0.289454</td>\n",
       "      <td>0.750931</td>\n",
       "      <td>0.212139</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>0.061049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011451</td>\n",
       "      <td>-0.503262</td>\n",
       "      <td>0.858820</td>\n",
       "      <td>0.007016</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>0.404042</td>\n",
       "      <td>1.087062</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.001720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79017</th>\n",
       "      <td>96</td>\n",
       "      <td>0.766219</td>\n",
       "      <td>0.152166</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>1.311442</td>\n",
       "      <td>0.022729</td>\n",
       "      <td>0.131301</td>\n",
       "      <td>0.662498</td>\n",
       "      <td>0.058250</td>\n",
       "      <td>0.100119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170568</td>\n",
       "      <td>-11.313364</td>\n",
       "      <td>0.751451</td>\n",
       "      <td>-0.003988</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>1.475238</td>\n",
       "      <td>9.327025</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.001469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136801</th>\n",
       "      <td>444</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>21.847603</td>\n",
       "      <td>0.141701</td>\n",
       "      <td>4.562675</td>\n",
       "      <td>0.090603</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.208841</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>1.192832</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.004025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2023-12-01</th>\n",
       "      <th>142960</th>\n",
       "      <td>875</td>\n",
       "      <td>0.494857</td>\n",
       "      <td>0.258809</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>2.561048</td>\n",
       "      <td>-0.019929</td>\n",
       "      <td>0.599322</td>\n",
       "      <td>0.790637</td>\n",
       "      <td>0.076776</td>\n",
       "      <td>0.234014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007516</td>\n",
       "      <td>-0.074240</td>\n",
       "      <td>0.615093</td>\n",
       "      <td>0.010144</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>1.452597</td>\n",
       "      <td>2.313842</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.004865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164883</th>\n",
       "      <td>335</td>\n",
       "      <td>0.440289</td>\n",
       "      <td>0.204966</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.369123</td>\n",
       "      <td>0.041082</td>\n",
       "      <td>0.509132</td>\n",
       "      <td>1.101150</td>\n",
       "      <td>0.053765</td>\n",
       "      <td>0.371868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040519</td>\n",
       "      <td>-0.331965</td>\n",
       "      <td>0.445832</td>\n",
       "      <td>-0.002505</td>\n",
       "      <td>0.006820</td>\n",
       "      <td>0.484558</td>\n",
       "      <td>6.825448</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>0.004572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56626</th>\n",
       "      <td>467</td>\n",
       "      <td>0.456242</td>\n",
       "      <td>0.073563</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>7.338437</td>\n",
       "      <td>0.106965</td>\n",
       "      <td>0.194904</td>\n",
       "      <td>0.601361</td>\n",
       "      <td>0.050950</td>\n",
       "      <td>0.026559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077962</td>\n",
       "      <td>-0.812357</td>\n",
       "      <td>0.310944</td>\n",
       "      <td>-0.004359</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.423431</td>\n",
       "      <td>3.953374</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.005337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103667</th>\n",
       "      <td>347</td>\n",
       "      <td>0.232903</td>\n",
       "      <td>0.142937</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>2.143037</td>\n",
       "      <td>-0.028275</td>\n",
       "      <td>0.774278</td>\n",
       "      <td>1.205285</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>0.361299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020596</td>\n",
       "      <td>0.472952</td>\n",
       "      <td>0.235576</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>0.504602</td>\n",
       "      <td>3.420703</td>\n",
       "      <td>0.006556</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>0.006052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172784</th>\n",
       "      <td>936</td>\n",
       "      <td>0.502752</td>\n",
       "      <td>0.448166</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>2.224959</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>1.989022</td>\n",
       "      <td>0.229889</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>0.893959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053687</td>\n",
       "      <td>-2.701708</td>\n",
       "      <td>0.587483</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.391692</td>\n",
       "      <td>1.081265</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172785 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   age         aliq_at        aliq_mat  ami_126d      at_be  \\\n",
       "t1_index   index                                                              \n",
       "2000-01-03 0       132        0.985818        0.059472  0.000026   1.260918   \n",
       "           2781    784        0.636280        0.419246  0.000106   3.002603   \n",
       "           79192   156        1.078982        0.497954  0.000215  12.300384   \n",
       "           79017    96        0.766219        0.152166  0.012623   1.311442   \n",
       "           136801  444  1000000.000000  1000000.000000  0.000583  21.847603   \n",
       "...                ...             ...             ...       ...        ...   \n",
       "2023-12-01 142960  875        0.494857        0.258809  0.000051   2.561048   \n",
       "           164883  335        0.440289        0.204966  0.000043   1.369123   \n",
       "           56626   467        0.456242        0.073563  0.000047   7.338437   \n",
       "           103667  347        0.232903        0.142937  0.000458   2.143037   \n",
       "           172784  936        0.502752        0.448166  0.000064   2.224959   \n",
       "\n",
       "                     at_gr1     at_me  at_turnover   be_gr1a     be_me  ...  \\\n",
       "t1_index   index                                                        ...   \n",
       "2000-01-03 0       0.651395  0.042021     1.028183  0.310450  0.033325  ...   \n",
       "           2781    0.003136  0.982853     1.561359 -0.007330  0.327334  ...   \n",
       "           79192   0.289454  0.750931     0.212139  0.029724  0.061049  ...   \n",
       "           79017   0.022729  0.131301     0.662498  0.058250  0.100119  ...   \n",
       "           136801  0.141701  4.562675     0.090603  0.005307  0.208841  ...   \n",
       "...                     ...       ...          ...       ...       ...  ...   \n",
       "2023-12-01 142960 -0.019929  0.599322     0.790637  0.076776  0.234014  ...   \n",
       "           164883  0.041082  0.509132     1.101150  0.053765  0.371868  ...   \n",
       "           56626   0.106965  0.194904     0.601361  0.050950  0.026559  ...   \n",
       "           103667 -0.028275  0.774278     1.205285  0.030875  0.361299  ...   \n",
       "           172784  0.033296  1.989022     0.229889 -0.000261  0.893959  ...   \n",
       "\n",
       "                     taccruals_at    taccruals_ni     tangibility  tax_gr1a  \\\n",
       "t1_index   index                                                              \n",
       "2000-01-03 0             0.132759        0.932668        0.287709  0.018174   \n",
       "           2781         -0.070334       -1.350656        0.571700  0.030609   \n",
       "           79192        -0.011451       -0.503262        0.858820  0.007016   \n",
       "           79017        -0.170568      -11.313364        0.751451 -0.003988   \n",
       "           136801  1000000.000000  1000000.000000  1000000.000000  0.000656   \n",
       "...                           ...             ...             ...       ...   \n",
       "2023-12-01 142960       -0.007516       -0.074240        0.615093  0.010144   \n",
       "           164883       -0.040519       -0.331965        0.445832 -0.002505   \n",
       "           56626        -0.077962       -0.812357        0.310944 -0.004359   \n",
       "           103667        0.020596        0.472952        0.235576  0.002153   \n",
       "           172784       -0.053687       -2.701708        0.587483  0.000052   \n",
       "\n",
       "                   turnover_126d  turnover_var_126d         z_score  \\\n",
       "t1_index   index                                                      \n",
       "2000-01-03 0            0.003022           0.336775       43.032362   \n",
       "           2781         0.003256           0.451566        3.381417   \n",
       "           79192        0.005098           0.404042        1.087062   \n",
       "           79017        0.007496           1.475238        9.327025   \n",
       "           136801       0.003407           1.192832  1000000.000000   \n",
       "...                          ...                ...             ...   \n",
       "2023-12-01 142960       0.008145           1.452597        2.313842   \n",
       "           164883       0.006820           0.484558        6.825448   \n",
       "           56626        0.006439           0.423431        3.953374   \n",
       "           103667       0.004803           0.504602        3.420703   \n",
       "           172784       0.007469           0.391692        1.081265   \n",
       "\n",
       "                   zero_trades_126d  zero_trades_21d  zero_trades_252d  \n",
       "t1_index   index                                                        \n",
       "2000-01-03 0               0.004157         0.005002          0.003226  \n",
       "           2781            0.003881         0.003926          0.003549  \n",
       "           79192           0.002407         0.003124          0.001720  \n",
       "           79017           0.001392         0.000767          0.001469  \n",
       "           136801          0.003737         0.005589          0.004025  \n",
       "...                             ...              ...               ...  \n",
       "2023-12-01 142960          0.004100         0.005428          0.004865  \n",
       "           164883          0.004906         0.004621          0.004572  \n",
       "           56626           0.005186         0.004429          0.005337  \n",
       "           103667          0.006556         0.005650          0.006052  \n",
       "           172784          0.004487         0.003086          0.004744  \n",
       "\n",
       "[172785 rows x 147 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['t1_index'] = Y['t1_index']\n",
    "X.reset_index(inplace=True)\n",
    "X.set_index(['t1_index', 'index'], inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X contains the feautes given and ADDED BY US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>stock_exret</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>t1</th>\n",
       "      <th>weight_attr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_index</th>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2000-01-03</th>\n",
       "      <th>0</th>\n",
       "      <td>0.018070</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133210</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>0.018070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>0.069806</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.602130</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>0.069806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79192</th>\n",
       "      <td>-0.066192</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.484446</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>0.066192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79017</th>\n",
       "      <td>0.825067</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.881480</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>0.825067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136801</th>\n",
       "      <td>0.093419</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>0.093419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2023-12-01</th>\n",
       "      <th>142960</th>\n",
       "      <td>0.015598</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.281077</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.015598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164883</th>\n",
       "      <td>0.068874</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.664075</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.068874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56626</th>\n",
       "      <td>0.110382</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217701</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.110382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103667</th>\n",
       "      <td>0.000132</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770597</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172784</th>\n",
       "      <td>0.042407</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936564</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.042407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172785 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   stock_exret  target  prediction  probability          t1  \\\n",
       "t1_index   index                                                              \n",
       "2000-01-03 0          0.018070       1         1.0     0.133210  2000-01-31   \n",
       "           2781       0.069806       1        -1.0     0.602130  2000-01-31   \n",
       "           79192     -0.066192      -1        -1.0     0.484446  2000-01-31   \n",
       "           79017      0.825067       1        -1.0     0.881480  2000-01-31   \n",
       "           136801     0.093419       1         1.0     0.819652  2000-01-31   \n",
       "...                        ...     ...         ...          ...         ...   \n",
       "2023-12-01 142960     0.015598       1        -1.0     0.281077  2023-12-29   \n",
       "           164883     0.068874       1         1.0     0.664075  2023-12-29   \n",
       "           56626      0.110382       1         1.0     0.217701  2023-12-29   \n",
       "           103667     0.000132       1         1.0     0.770597  2023-12-29   \n",
       "           172784     0.042407       1         1.0     0.936564  2023-12-29   \n",
       "\n",
       "                   weight_attr  \n",
       "t1_index   index                \n",
       "2000-01-03 0          0.018070  \n",
       "           2781       0.069806  \n",
       "           79192      0.066192  \n",
       "           79017      0.825067  \n",
       "           136801     0.093419  \n",
       "...                        ...  \n",
       "2023-12-01 142960     0.015598  \n",
       "           164883     0.068874  \n",
       "           56626      0.110382  \n",
       "           103667     0.000132  \n",
       "           172784     0.042407  \n",
       "\n",
       "[172785 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Y.reset_index()\n",
    "Y.set_index(['t1_index', 'index'], inplace=True)\n",
    "Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currently, in $Y$,\n",
    "\n",
    "*prediction* and *probability* are randomly generated, those are the columns\n",
    "we must fill for the investment perdiod (2008-) we our true probabilities and predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WE WANT TO PREDICT TARGET, which is simply the sign of stock_exret\n",
    "\n",
    "## Weight_attr IS SO IMPORANT, PLEASE DON'T IGNORE \n",
    "\n",
    "As Uday did in feature importance, this weight_attr must be rescaled for the \n",
    "training period. Right now, it is scaled for the whole dataset, you must reajust\n",
    "it for the training period such that the suym of the weight = Size of the training period\n",
    "\n",
    "*= X_train.shape[0]/X_train['weight_attr'].sum()\n",
    "\n",
    "Uday did it I believe\n",
    "\n",
    "Refer to section 4.6 if you have any doubts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "The method is explained in the FIAM instructions, please refer to pages\\\n",
    "6 and 7, sections **Performance evaluation** AND **Training Procedures**\\\n",
    "(especially training procedures)\n",
    "\n",
    "As they mention it in the doc, they provided an implementation of the method,\n",
    "\n",
    "penalized_linear_hackathon.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import PredefinedSplit, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from scipy.stats import randint, uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stock_vars = ['ret_1_0', 'prc_highprc_252d', 'seas_1_1na', 'rmax5_21d']  # List of features\n",
    "stock_vars = [\n",
    "    # Historical Returns & Momentum Indicators\n",
    "    'ret_12_1',            # 12-month return excluding the last month (momentum indicator)\n",
    "    'ret_60_12',           # Long-term momentum (5-year minus 1-year returns)\n",
    "\n",
    "    # Valuation Metrics\n",
    "    'market_equity',        # Market capitalization (size factor)\n",
    "    'intrinsic_value',      # Fundamental valuation metric, useful for identifying mispriced stocks\n",
    "    'be_me',                # Book-to-market ratio (value factor)\n",
    "\n",
    "    # Profitability Indicators\n",
    "    'ebit_sale',            # Operating profitability ratio (quality factor)\n",
    "    # 'eps_actual',           # Actual earnings per share (earnings indicator)\n",
    "\n",
    "    # Growth Indicators\n",
    "    'sale_gr1',             # 1-year sales growth (growth factor)\n",
    "    'emp_gr1',              # 1-year employee growth (operational growth efficiency)\n",
    "\n",
    "    # Financial Health & Leverage\n",
    "    'netdebt_me',           # Net debt-to-market equity (leverage risk indicator)\n",
    "    'z_score',              # Altman Z-score (financial distress risk indicator)\n",
    "\n",
    "    # Risk & Volatility Measures\n",
    "    'beta_60m',             # 5-year beta (systematic risk measure)\n",
    "    'ivol_capm_21d',        # Idiosyncratic volatility (measure of unsystematic risk)\n",
    "    'rvol_21d',             # 21-day return volatility (short-term risk measure)\n",
    "\n",
    "    # Liquidity & Market Microstructure\n",
    "    'dolvol_126d',          # Dollar trading volume over 126 days (liquidity factor)\n",
    "    'zero_trades_252d',     # Frequency of zero-return days over a year (illiquidity proxy)\n",
    "\n",
    "    # Quality & Profitability Measures\n",
    "    'f_score',              # Piotroski F-score (financial health score)\n",
    "    'qmj_prof',             # Quality-minus-junk (profitability quality factor)\n",
    "\n",
    "    # Behavioral & Mispricing Indicators\n",
    "    'mispricing_perf',      # Performance-based mispricing indicator\n",
    "    'age'                   # Age of the firm (younger firms tend to be riskier but with potential growth)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tgt_var = 'target'  # Target variable\n",
    "\n",
    "starting = pd.to_datetime(\"20000101\", format=\"%Y%m%d\")\n",
    "counter = 0\n",
    "pred_out = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X.index = pd.MultiIndex.from_tuples(\n",
    "    [(pd.to_datetime(t1_index), other_index) for t1_index, other_index in X.index]\n",
    ")\n",
    "Y.index = pd.MultiIndex.from_tuples(\n",
    "    [(pd.to_datetime(t1_index), other_index) for t1_index, other_index in Y.index]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Start: 2000-01-01 00:00:00, Train End: 2008-01-01 00:00:00, Val Start: 2008-01-01 00:00:00, Val End: 2010-01-01 00:00:00, Test Start: 2010-01-01 00:00:00, Test End: 2011-01-01 00:00:00\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=116, max_features=0.8796910002727693, max_samples=0.696850157946487, n_estimators=92; total time= 9.9min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 83\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Define the optimizer\u001b[39;00m\n\u001b[1;32m     72\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     73\u001b[0m bagging_clf,\n\u001b[1;32m     74\u001b[0m param_distributions\u001b[38;5;241m=\u001b[39mparam_distributions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     80\u001b[0m )   \n\u001b[0;32m---> 83\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtgt_var\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample_weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train_val\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_attr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m best_estimator \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     93\u001b[0m best_estimator\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     94\u001b[0m     X_train_val,\n\u001b[1;32m     95\u001b[0m     Y_train_val[tgt_var]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     96\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mY_train_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_attr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     97\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:936\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    934\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/ensemble/_bagging.py:338\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[1;32m    330\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    331\u001b[0m     X,\n\u001b[1;32m    332\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    337\u001b[0m )\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/ensemble/_bagging.py:473\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    470\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[0;32m--> 473\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    492\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[1;32m    493\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/financial_math/lib/python3.8/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/financial_math/lib/python3.8/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/financial_math/lib/python3.8/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Estimation with expanding window\n",
    "while (starting + pd.DateOffset(years=11 + counter)) <= pd.to_datetime(\"20240101\", format=\"%Y%m%d\"):\n",
    "    # For testing purposes\n",
    "    # if counter == 1:\n",
    "    #     break\n",
    "\n",
    "    cutoff = [\n",
    "        starting,\n",
    "        starting + pd.DateOffset(years=8 + counter),  # Training set end date\n",
    "        starting + pd.DateOffset(years=10 + counter),  # Validation set end date\n",
    "        starting + pd.DateOffset(years=11 + counter),  # Test set end date\n",
    "    ]\n",
    "\n",
    "    print(f\"Train Start: {cutoff[0]}, Train End: {cutoff[1]}, Val Start: {cutoff[1]}, Val End: {cutoff[2]}, Test Start: {cutoff[2]}, Test End: {cutoff[3]}\")\n",
    "\n",
    "    # Cut the sample into training, validation, and testing sets\n",
    "    X_train = X[(X.index.get_level_values(0) >= cutoff[0]) & (X.index.get_level_values(0) < cutoff[1])]\n",
    "    X_validate = X[(X.index.get_level_values(0) >= cutoff[1]) & (X.index.get_level_values(0) < cutoff[2])]\n",
    "    X_test = X[(X.index.get_level_values(0) >= cutoff[2]) & (X.index.get_level_values(0) < cutoff[3])]\n",
    "\n",
    "    Y_train = Y[(Y.index.get_level_values(0) >= cutoff[0]) & (Y.index.get_level_values(0) < cutoff[1])]\n",
    "    Y_validate = Y[(Y.index.get_level_values(0) >= cutoff[1]) & (Y.index.get_level_values(0) < cutoff[2])]\n",
    "    Y_test = Y[(Y.index.get_level_values(0) >= cutoff[2]) & (Y.index.get_level_values(0) < cutoff[3])]\n",
    "\n",
    "    # # Adjust sample weights\n",
    "    # Y_train['weight_attr'] *= Y_train.shape[0] / Y_train['weight_attr'].sum()\n",
    "    # Y_validate['weight_attr'] *= Y_validate.shape[0] / Y_validate['weight_attr'].sum()\n",
    "    # Y_test['weight_attr'] *= Y_test.shape[0] / Y_test['weight_attr'].sum()\n",
    "\n",
    "\n",
    "    X_train_vals = X_train[stock_vars].values\n",
    "    X_validate_vals = X_validate[stock_vars].values\n",
    "    X_test_vals = X_test[stock_vars].values\n",
    "\n",
    "    X_train_val = np.vstack([X_train_vals, X_validate_vals])\n",
    "    Y_train_val = pd.concat([Y_train, Y_validate])\n",
    "\n",
    "    # Create test_fold \n",
    "    test_fold = np.concatenate([\n",
    "        np.full(len(X_train_vals), -1),  # training set indices\n",
    "        np.zeros(len(X_validate_vals))   # validation set indices\n",
    "    ])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "\n",
    "\n",
    "    base_rf = RandomForestClassifier(\n",
    "        criterion=\"entropy\",\n",
    "        bootstrap=False,\n",
    "        class_weight=\"balanced_subsample\"\n",
    "    )\n",
    "\n",
    "\n",
    "    bagging_clf = BaggingClassifier(\n",
    "        estimator=base_rf,\n",
    "        oob_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    " \n",
    "    param_distributions = {\n",
    "    'estimator__n_estimators': randint(10, 1000),\n",
    "    'estimator__max_depth': randint(5, 50),\n",
    "    'estimator__min_samples_split': randint(2, 10),\n",
    "    'estimator__min_samples_leaf': randint(1, 5),\n",
    "    'estimator__max_features': ['sqrt', 'log2'],  \n",
    "    'n_estimators': randint(10, 100),  \n",
    "    'max_samples': uniform(0.1, 1.0),  \n",
    "    'max_features': uniform(0.1, 1.0)  \n",
    "    }\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = RandomizedSearchCV(\n",
    "    bagging_clf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=1,  \n",
    "    cv=ps,      # Use predefined split\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    "    )   \n",
    "\n",
    "\n",
    "    optimizer.fit(\n",
    "        X_train_val,\n",
    "        Y_train_val[tgt_var].values,\n",
    "        **{'sample_weight': Y_train_val['weight_attr'].values}\n",
    "    )\n",
    "\n",
    "\n",
    "    best_estimator = optimizer.best_estimator_\n",
    "\n",
    "\n",
    "    best_estimator.fit(\n",
    "        X_train_val,\n",
    "        Y_train_val[tgt_var].values,\n",
    "        sample_weight=Y_train_val['weight_attr'].values\n",
    "    )\n",
    "\n",
    "    # Predict on test set\n",
    "    prob = best_estimator.predict_proba(X_test_vals)\n",
    "    score_ = -log_loss(Y_test[tgt_var].values, prob, sample_weight=Y_test[\"weight_attr\"].values, labels=best_estimator.classes_)\n",
    "    print(\"Log Loss on Test Set:\", score_)\n",
    "\n",
    "    # Store predictions in Y_test\n",
    "    Y_test['prediction'] = best_estimator.predict(X_test_vals)\n",
    "    Y_test['probability'] = prob.max(axis=1)\n",
    "\n",
    "    # print(\"Predictions on Test Set:\")\n",
    "    # print(Y_test['prediction'])\n",
    "    # print(\"Probabilities on Test Set:\")\n",
    "    # print(Y_test['probability'])\n",
    "    # print(\"Prediction Probabilities:\")\n",
    "    # print(prob)\n",
    "\n",
    " \n",
    "    pred_out = pred_out.append(Y_test[['prediction', 'probability']])\n",
    "    pred_out.to_csv(\"../objects/predictions.csv\")\n",
    "\n",
    "\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use one of the following. For clarification, refer to **6.4**\n",
    "\n",
    "I believe clf2 is the best one\n",
    "\n",
    "### This is from my deprado repo, *ch_06.ipynb*\n",
    "\n",
    "```python\n",
    "# Libraries\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dataset\n",
    "X, Y = f_ch8.getTestData(n_features=40, n_informative=3, n_redundant=30, n_samples=10000)\n",
    "Y = Y[\"bin\"]\n",
    "\n",
    "# usual RF\n",
    "clf0 = RandomForestClassifier(\n",
    "    n_estimators=1_000,  # 1_000 trees\n",
    "    class_weight=\"balanced_subsample\",  # prevent minority class from being ignored\n",
    "    criterion=\"entropy\"  # information gain\n",
    ")\n",
    "\n",
    "# Ensemble of estimators with base estimator as a decision tree\n",
    "clf1 = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",  # information gain\n",
    "    max_features=\"sqrt\",  # sqrt(n_features) to force diversity among trees\n",
    "    class_weight=\"balanced\"  # prevent minority class from being ignored\n",
    ")\n",
    "clf1 = BaggingClassifier(\n",
    "    estimator=clf1,  # base estimator\n",
    "    n_estimators=1_000,  # 1_000 trees\n",
    "    max_samples=0.6,  # average uniqueness\n",
    "    max_features=1.0  # all features for bagging\n",
    ")\n",
    "\n",
    "# Bagging classifier on RF where max_samples is set to average uniqueness\n",
    "clf2 = RandomForestClassifier(\n",
    "    n_estimators=1,  # 1 tree\n",
    "    criterion=\"entropy\",  # information gain\n",
    "    bootstrap=False,  # no bootstrap\n",
    "    class_weight=\"balanced_subsample\"  # prevent minority class from being ignored\n",
    ")\n",
    "\n",
    "clf2 = BaggingClassifier(\n",
    "    estimator=clf2,  # base estimator\n",
    "    n_estimators=1_000,  # 1_000 trees\n",
    "    max_samples=1.0,  # average uniqueness\n",
    "    max_features=1.0  # all features for bagging\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning\n",
    "\n",
    "### Here is why the weights are so important\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to *9.4* , you can use accuracy, but negative log likelihood is suggested,\\\n",
    "since it takes into account the probability of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hyperparaemtes, i believe you guys can figure out better than me what\n",
    "to set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please be aware of the bugs mentioned in\n",
    "\n",
    "- 7.5 BUGS IN SKLEARN’S CROSS-VALIDATION\n",
    "- SNIPPET 9.2 AN ENHANCED PIPELINE CLASS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I'M AVAILABLE ALL DAY, PLEASE ASK ME ANYTHING, LET'S GOOOOO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time Window 0:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2008-01-01 00:00:00, Val Start: 2008-01-01 00:00:00, Val End: 2010-01-01 00:00:00, Test Start: 2010-01-01 00:00:00, Test End: 2011-01-01 00:00:00\n",
      "Processing Time Window 2:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2010-01-01 00:00:00, Val Start: 2010-01-01 00:00:00, Val End: 2012-01-01 00:00:00, Test Start: 2012-01-01 00:00:00, Test End: 2013-01-01 00:00:00\n",
      "Processing Time Window 3:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2011-01-01 00:00:00, Val Start: 2011-01-01 00:00:00, Val End: 2013-01-01 00:00:00, Test Start: 2013-01-01 00:00:00, Test End: 2014-01-01 00:00:00\n",
      "Processing Time Window 1:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2009-01-01 00:00:00, Val Start: 2009-01-01 00:00:00, Val End: 2011-01-01 00:00:00, Test Start: 2011-01-01 00:00:00, Test End: 2012-01-01 00:00:00\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=12.1min\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=12.9min\n",
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 3.0min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=15.5min\n",
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 3.3min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=16.8min\n",
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 3.7min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 4.1min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time= 9.0min\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time= 9.8min\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time=11.7min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time= 8.0min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time=  57.3s\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time=13.0min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time= 9.0min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 1.1min\n",
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time= 7.0min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time=10.6min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 1.2min\n",
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 2.9min\n",
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time= 7.9min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 2.6min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time=11.8min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 1.3min\n",
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 3.2min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 2.7min\n",
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time= 9.0min\n",
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 3.8min\n",
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time=10.2min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 3.4min\n",
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 4.3min\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=16.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.51890649 0.51833163        nan 0.52235565 0.52203628 0.52567706\n",
      " 0.52376086 0.52542156 0.52452734 0.51980072]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss on Test Set: -0.6816387098299219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time Window 4:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2012-01-01 00:00:00, Val Start: 2012-01-01 00:00:00, Val End: 2014-01-01 00:00:00, Test Start: 2014-01-01 00:00:00, Test End: 2015-01-01 00:00:00\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 3.7min\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=17.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.53913151 0.5316573         nan 0.52294768 0.51652357 0.4902094\n",
      " 0.50373711 0.50948175 0.54110816 0.51491754]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss on Test Set: -0.6882967004168054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time Window 5:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2013-01-01 00:00:00, Val Start: 2013-01-01 00:00:00, Val End: 2015-01-01 00:00:00, Test Start: 2015-01-01 00:00:00, Test End: 2016-01-01 00:00:00\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=21.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.55159267 0.5557127         nan 0.55030132 0.54894847 0.54630427\n",
      " 0.54894847 0.54495142 0.55263805 0.54876399]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=17.8min\n",
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 4.5min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=23.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.56945383 0.5682251         nan 0.56447748 0.56036125 0.55206733\n",
      " 0.55409473 0.55427904 0.55679794 0.56109848]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss on Test Set: -0.6788085931331082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time Window 6:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2014-01-01 00:00:00, Val Start: 2014-01-01 00:00:00, Val End: 2016-01-01 00:00:00, Test Start: 2016-01-01 00:00:00, Test End: 2017-01-01 00:00:00\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=20.0min\n",
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 5.0min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time=14.4min\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=21.9min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time=13.1min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 1.5min\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time=16.2min\n",
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 5.5min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time=11.3min\n",
      "Log Loss on Test Set: -0.6509621751193377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time Window 7:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2015-01-01 00:00:00, Val Start: 2015-01-01 00:00:00, Val End: 2017-01-01 00:00:00, Test Start: 2017-01-01 00:00:00, Test End: 2018-01-01 00:00:00\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time=14.7min\n",
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 4.6min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 1.6min\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time=17.7min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 4.3min\n",
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time=12.5min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time=15.6min\n",
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 5.0min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 1.8min\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=23.7min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 4.8min\n",
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 6.1min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=26.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.60144619 0.60527435        nan 0.59190618 0.58917178 0.59731421\n",
      " 0.6263596  0.59652428 0.60648964 0.57434526]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time=13.9min\n",
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 5.7min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 5.3min\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time=19.4min\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=29.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.60696818 0.60859851        nan 0.58794759 0.58384156 0.58305658\n",
      " 0.60763239 0.58366041 0.61747479 0.5664513 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss on Test Set: -0.687084489519755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time Window 8:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2016-01-01 00:00:00, Val Start: 2016-01-01 00:00:00, Val End: 2018-01-01 00:00:00, Test Start: 2018-01-01 00:00:00, Test End: 2019-01-01 00:00:00\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time=17.5min\n",
      "Log Loss on Test Set: -0.6999105564419685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time Window 9:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2017-01-01 00:00:00, Val Start: 2017-01-01 00:00:00, Val End: 2019-01-01 00:00:00, Test Start: 2019-01-01 00:00:00, Test End: 2020-01-01 00:00:00\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 1.9min\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=32.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.53913254 0.53755755        nan 0.53755755 0.53174219 0.52429125\n",
      " 0.53701236 0.52804701 0.54004119 0.52919796]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time=15.4min\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=26.8min\n",
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 6.2min\n",
      "Log Loss on Test Set: -0.677934073477907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time Window 10:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2018-01-01 00:00:00, Val Start: 2018-01-01 00:00:00, Val End: 2020-01-01 00:00:00, Test Start: 2020-01-01 00:00:00, Test End: 2021-01-01 00:00:00\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 6.7min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=29.0min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 5.8min\n",
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 7.2min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time=21.3min\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=31.3min\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time=23.1min\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=35.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.53389831 0.53090728        nan 0.52916251 0.52187188 0.51682453\n",
      " 0.53389831 0.5219342  0.53670239 0.52168495]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 7.8min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time=18.7min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 2.0min\n",
      "Log Loss on Test Set: -0.671803857858426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time Window 11:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2019-01-01 00:00:00, Val Start: 2019-01-01 00:00:00, Val End: 2021-01-01 00:00:00, Test Start: 2021-01-01 00:00:00, Test End: 2022-01-01 00:00:00\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time=20.2min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 2.1min\n",
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time=16.2min\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time=24.6min\n",
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 6.4min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 6.3min\n",
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time=16.5min\n",
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 7.0min\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=32.9min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time=21.2min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 6.6min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 2.3min\n",
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 8.1min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time=17.9min\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=37.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.58681662 0.58070597        nan 0.57407528 0.56438926 0.56113892\n",
      " 0.58876682 0.56419424 0.59539752 0.54911266]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 7.5min\n",
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time=25.9min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 7.3min\n",
      "Log Loss on Test Set: -0.7096084877971518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time Window 12:\n",
      "Train Start: 2000-01-01 00:00:00, Train End: 2020-01-01 00:00:00, Val Start: 2020-01-01 00:00:00, Val End: 2022-01-01 00:00:00, Test Start: 2022-01-01 00:00:00, Test End: 2023-01-01 00:00:00\n",
      "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=40.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.547537   0.55132104        nan 0.54463139 0.54280695 0.54807757\n",
      " 0.55186161 0.5492263  0.5492263  0.53800932]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time=22.8min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 2.5min\n",
      "[CV] END estimator__max_depth=43, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=8, estimator__n_estimators=81, max_features=0.6986584841970366, max_samples=0.2560186404424365, n_estimators=92; total time=36.1min\n",
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time=19.9min\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=44.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.55965232 0.55965232        nan 0.55881116 0.55474555 0.54766578\n",
      " 0.5622459  0.55180149 0.562316   0.55131081]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss on Test Set: -0.6896437476813179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=27, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=9, estimator__n_estimators=33, max_features=0.7508884729488529, max_samples=0.15641157902710026, n_estimators=97; total time= 8.8min\n",
      "[CV] END estimator__max_depth=48, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=3, estimator__n_estimators=73, max_features=1.0922115592912176, max_samples=0.7174815096277165, n_estimators=67; total time=   0.0s\n",
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 8.0min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 7.6min\n",
      "Log Loss on Test Set: -0.7116206123181069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=26, estimator__max_features=sqrt, estimator__min_samples_leaf=4, estimator__min_samples_split=2, estimator__n_estimators=58, max_features=0.6247746602583891, max_samples=0.49986097171525545, n_estimators=69; total time=26.6min\n",
      "[CV] END estimator__max_depth=20, estimator__max_features=sqrt, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=56, max_features=0.7183860093330873, max_samples=0.4824619912671627, n_estimators=73; total time=22.7min\n",
      "[CV] END estimator__max_depth=7, estimator__max_features=sqrt, estimator__min_samples_leaf=3, estimator__min_samples_split=8, estimator__n_estimators=30, max_features=0.550499251969543, max_samples=0.11326496115986653, n_estimators=98; total time= 2.4min\n",
      "[CV] END estimator__max_depth=22, estimator__max_features=log2, estimator__min_samples_leaf=4, estimator__min_samples_split=3, estimator__n_estimators=83, max_features=0.9948273504276488, max_samples=0.6978999788110851, n_estimators=57; total time=43.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0.0, 1.0]. Got 1.0922115592912176 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.51874129 0.50436441        nan 0.49548889 0.48169882 0.47773784\n",
      " 0.51881464 0.48037849 0.54822856 0.47700433]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=18, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=2, estimator__n_estimators=99, max_features=0.19767211400638388, max_samples=0.7842330265121569, n_estimators=69; total time=19.5min\n",
      "Log Loss on Test Set: -0.6633656394823757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_28953/1475686741.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=11, estimator__max_features=log2, estimator__min_samples_leaf=1, estimator__min_samples_split=9, estimator__n_estimators=56, max_features=0.27336465350777206, max_samples=0.49106060757324077, n_estimators=59; total time= 7.8min\n",
      "[CV] END estimator__max_depth=44, estimator__max_features=log2, estimator__min_samples_leaf=2, estimator__min_samples_split=7, estimator__n_estimators=15, max_features=0.3079416628681888, max_samples=0.6677003278199914, n_estimators=72; total time= 7.5min\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# ... (your existing imports and data loading code)\n",
    "\n",
    "def process_time_window(counter):\n",
    "    # Define your starting point\n",
    "    starting = pd.to_datetime(\"2000-01-01\")\n",
    "    \n",
    "    # Calculate cutoff dates\n",
    "    cutoff = [\n",
    "        starting,\n",
    "        starting + pd.DateOffset(years=8 + counter),  # Training set end date\n",
    "        starting + pd.DateOffset(years=10 + counter),  # Validation set end date\n",
    "        starting + pd.DateOffset(years=11 + counter),  # Test set end date\n",
    "    ]\n",
    "\n",
    "    print(f\"Processing Time Window {counter}:\")\n",
    "    print(f\"Train Start: {cutoff[0]}, Train End: {cutoff[1]}, Val Start: {cutoff[1]}, Val End: {cutoff[2]}, Test Start: {cutoff[2]}, Test End: {cutoff[3]}\")\n",
    "\n",
    "    # Split the data\n",
    "    X_train = X[(X.index.get_level_values(0) >= cutoff[0]) & (X.index.get_level_values(0) < cutoff[1])]\n",
    "    X_validate = X[(X.index.get_level_values(0) >= cutoff[1]) & (X.index.get_level_values(0) < cutoff[2])]\n",
    "    X_test = X[(X.index.get_level_values(0) >= cutoff[2]) & (X.index.get_level_values(0) < cutoff[3])]\n",
    "\n",
    "    Y_train = Y[(Y.index.get_level_values(0) >= cutoff[0]) & (Y.index.get_level_values(0) < cutoff[1])]\n",
    "    Y_validate = Y[(Y.index.get_level_values(0) >= cutoff[1]) & (Y.index.get_level_values(0) < cutoff[2])]\n",
    "    Y_test = Y[(Y.index.get_level_values(0) >= cutoff[2]) & (Y.index.get_level_values(0) < cutoff[3])]\n",
    "\n",
    "    X_train_vals = X_train[stock_vars].values\n",
    "    X_validate_vals = X_validate[stock_vars].values\n",
    "    X_test_vals = X_test[stock_vars].values\n",
    "\n",
    "    X_train_val = np.vstack([X_train_vals, X_validate_vals])\n",
    "    Y_train_val = pd.concat([Y_train, Y_validate])\n",
    "\n",
    "    # Create test_fold \n",
    "    test_fold = np.concatenate([\n",
    "        np.full(len(X_train_vals), -1),  # training set indices\n",
    "        np.zeros(len(X_validate_vals))   # validation set indices\n",
    "    ])\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "\n",
    "    base_rf = RandomForestClassifier(\n",
    "        criterion=\"entropy\",\n",
    "        bootstrap=False,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        n_jobs=1  # Limit to 1 core per estimator\n",
    "    )\n",
    "\n",
    "    bagging_clf = BaggingClassifier(\n",
    "        estimator=base_rf,\n",
    "        oob_score=True,\n",
    "        n_jobs=1  # Limit to 1 core per BaggingClassifier\n",
    "    )\n",
    "\n",
    "    param_distributions = {\n",
    "        'estimator__n_estimators': randint(10, 100),\n",
    "        'estimator__max_depth': randint(5, 50),\n",
    "        'estimator__min_samples_split': randint(2, 10),\n",
    "        'estimator__min_samples_leaf': randint(1, 5),\n",
    "        'estimator__max_features': ['sqrt', 'log2'],  \n",
    "        'n_estimators': randint(10, 100),  \n",
    "        'max_samples': uniform(0.1, 1.0),  \n",
    "        'max_features': uniform(0.1, 1.0)  \n",
    "    }\n",
    "\n",
    "    optimizer = RandomizedSearchCV(\n",
    "        bagging_clf,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=10,  # Increase iterations for better search\n",
    "        cv=ps,      # Use predefined split\n",
    "        n_jobs=1,   # Limit to 1 core to prevent nested parallelism\n",
    "        verbose=2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    optimizer.fit(\n",
    "        X_train_val,\n",
    "        Y_train_val[tgt_var].values,\n",
    "        sample_weight=Y_train_val['weight_attr'].values\n",
    "    )\n",
    "\n",
    "    best_estimator = optimizer.best_estimator_\n",
    "\n",
    "    best_estimator.fit(\n",
    "        X_train_val,\n",
    "        Y_train_val[tgt_var].values,\n",
    "        sample_weight=Y_train_val['weight_attr'].values\n",
    "    )\n",
    "\n",
    "    # Predict on test set\n",
    "    prob = best_estimator.predict_proba(X_test_vals)\n",
    "    score_ = -log_loss(Y_test[tgt_var].values, prob, sample_weight=Y_test[\"weight_attr\"].values, labels=best_estimator.classes_)\n",
    "    print(\"Log Loss on Test Set:\", score_)\n",
    "\n",
    "    # Store predictions in Y_test\n",
    "    Y_test['prediction'] = best_estimator.predict(X_test_vals)\n",
    "    Y_test['probability'] = prob.max(axis=1)\n",
    "\n",
    "    return Y_test[['prediction', 'probability']]\n",
    "\n",
    "# Prepare the list of counters\n",
    "starting = pd.to_datetime(\"2000-01-01\")\n",
    "end_date = pd.to_datetime(\"2024-01-01\")\n",
    "max_counter = ((end_date - starting).days // 365) - 11  # Adjust based on your data\n",
    "counters_list = list(range(max_counter))\n",
    "\n",
    "import multiprocessing\n",
    "print(f\"Number of CPU cores available: {multiprocessing.cpu_count()}\")\n",
    "\n",
    "# Run in parallel\n",
    "n_parallel_jobs = 4  # Adjust this number based on your CPU cores\n",
    "results = Parallel(n_jobs=n_parallel_jobs)(\n",
    "    delayed(process_time_window)(counter)\n",
    "    for counter in counters_list\n",
    ")\n",
    "\n",
    "# Combine results\n",
    "pred_out = pd.concat(results)\n",
    "pred_out.to_csv(\"../objects/predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financial_math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
