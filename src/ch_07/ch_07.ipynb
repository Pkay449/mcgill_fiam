{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2024-09-07T12:30:22.261252-04:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.19\n",
      "IPython version      : 8.12.2\n",
      "\n",
      "Compiler    : Clang 16.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 23.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/8v9qcjfx15g5ftmsy5n0qrq80000gn/T/ipykernel_91055/2173331131.py:46: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-talk')\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# import standard libs\n",
    "from IPython.display import display\n",
    "from IPython.core.debugger import set_trace as bp\n",
    "from pathlib import PurePath, Path\n",
    "import sys\n",
    "import time\n",
    "from collections import OrderedDict as od\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "\n",
    "# import python scientific stack\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "pd.set_option('display.max_rows', 10)\n",
    "from dask import dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from multiprocessing import cpu_count\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from numba import jit\n",
    "import math\n",
    "# import ffn\n",
    "\n",
    "\n",
    "# import visual tools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "plt.style.use('bmh')\n",
    "#plt.rcParams['font.family'] = 'DejaVu Sans Mono'\n",
    "plt.rcParams['font.size'] = 9.5\n",
    "plt.rcParams['font.weight'] = 'medium'\n",
    "plt.rcParams['figure.figsize'] = 10,7\n",
    "blue, green, red, purple, gold, teal = sns.color_palette('colorblind', 6)\n",
    "\n",
    "RANDOM_STATE = 777\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to sys.path: /Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management\n",
      "Config path added to sys.path: /Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management/config\n",
      "Current sys.path: ['/Users/paulkelendji/miniconda3/envs/financial_math/lib/python38.zip', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/lib-dynload', '', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/setuptools/_vendor', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management/config']\n",
      "Project root added to sys.path: /Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management\n",
      "Config path added to sys.path: /Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management/config\n",
      "Current sys.path: ['/Users/paulkelendji/miniconda3/envs/financial_math/lib/python38.zip', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/lib-dynload', '', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/setuptools/_vendor', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management/config', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management/config']\n",
      "Project root added to sys.path: /Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management\n",
      "Config path added to sys.path: /Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management/config\n",
      "Current sys.path: ['/Users/paulkelendji/miniconda3/envs/financial_math/lib/python38.zip', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/lib-dynload', '', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages', '/Users/paulkelendji/miniconda3/envs/financial_math/lib/python3.8/site-packages/setuptools/_vendor', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management/config', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management/config', '/Users/paulkelendji/Desktop/GitHub_paul', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management', '/Users/paulkelendji/Desktop/GitHub_paul/ML-Asset_Management/config']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Run the setup script\n",
    "%run ../../config/setup_project.py\n",
    "\n",
    "# Call the function to set up the project path\n",
    "setup_project_path()\n",
    "\n",
    "# Now you can import your modules\n",
    "from src.utils import helper as h_\n",
    "import src.ch_02.code_ch_02 as f_ch2\n",
    "import src.ch_03.code_ch_03 as f_ch3\n",
    "import src.ch_04.code_ch_04 as f_ch4\n",
    "import src.ch_05.code_ch_05 as f_ch5\n",
    "import src.ch_06.code_ch_06 as f_ch6\n",
    "import src.ch_07.code_ch_07 as f_ch7\n",
    "import src.ch_08.code_ch_08 as f_ch8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, cont = f_ch8.getTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>w</th>\n",
       "      <th>t1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1986-05-12 12:30:25.451645</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1986-05-18 14:25:15.597123940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-05-13 12:30:25.451645</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1986-05-15 23:00:51.365790475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-05-14 12:30:25.451645</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1986-05-24 01:26:29.359801697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-05-15 12:30:25.451645</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1986-05-17 10:07:02.236412876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-05-16 12:30:25.451645</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1986-05-26 09:08:38.491527716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            bin       w                            t1\n",
       "1986-05-12 12:30:25.451645    0  0.0001 1986-05-18 14:25:15.597123940\n",
       "1986-05-13 12:30:25.451645    0  0.0001 1986-05-15 23:00:51.365790475\n",
       "1986-05-14 12:30:25.451645    0  0.0001 1986-05-24 01:26:29.359801697\n",
       "1986-05-15 12:30:25.451645    0  0.0001 1986-05-17 10:07:02.236412876\n",
       "1986-05-16 12:30:25.451645    0  0.0001 1986-05-26 09:08:38.491527716"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 Why is shuffling a dataset before conducting k-fold CV generally a bad idea in finance? What is the purpose of shuffling? Why does shuffling defeat the purpose of k-fold CV in financial datasets?\n",
    "\n",
    "### Answer:\n",
    "\n",
    "Shuffling could to obtain training data with a time later than the test data, which is not realistic in finance. It would cause data leakage and the results would be biased.\n",
    "\n",
    "## Chat GPT\n",
    "\n",
    "Your answer is on the right track, but we can enhance and clarify it by adding more context and detail. Here’s an improved version of the answer:\n",
    "\n",
    "---\n",
    "\n",
    "### **Answer:**\n",
    "\n",
    "In finance, time plays a critical role in how data should be treated. Shuffling the dataset before performing k-fold cross-validation (CV) can introduce issues because it disrupts the temporal ordering of the data. In financial datasets, the past is used to predict the future. If shuffling occurs, this temporal structure is broken, and training data could inadvertently include observations from the future (relative to the test data), leading to **data leakage**. \n",
    "\n",
    "The purpose of shuffling in machine learning is typically to ensure that each fold in k-fold CV contains a representative sample of the entire dataset, reducing biases caused by data ordering. However, in finance, **data dependency** and **autocorrelation** (e.g., stock prices often depend on previous values) mean that shuffling would violate the assumption that future prices are unknown at the time predictions are made. This would create **look-ahead bias**, where information from the future is used to predict the past, resulting in unrealistically high performance metrics and **biased results**.\n",
    "\n",
    "Therefore, shuffling defeats the purpose of k-fold CV in financial datasets because it disrupts the temporal relationship between observations, making the model evaluation invalid for real-world financial predictions, where such time-based dependencies must be preserved.\n",
    "\n",
    "---\n",
    "\n",
    "This version provides more context on why shuffling is done in non-financial datasets and explicitly connects shuffling to the potential pitfalls (data leakage and look-ahead bias) when used improperly in finance.\n",
    "\n",
    "---\n",
    "\n",
    "**Data leakage** and **look-ahead bias** are closely related concepts, but they are not exactly the same. Both lead to overly optimistic model performance, but they differ in how they occur.\n",
    "\n",
    "### **Data Leakage**:\n",
    "Data leakage occurs when information from outside the training dataset leaks into the model during training, allowing the model to \"cheat\" by learning patterns it wouldn’t normally have access to in a real-world scenario. Leakage can happen in many forms:\n",
    "1. **Feature leakage**: When the model is trained on features that contain future information or other data that should not be available at the time of prediction. For example, using a feature that contains future stock prices in a model designed to predict future returns would cause data leakage.\n",
    "2. **Target leakage**: This happens when the model has access to the target variable in an indirect form. For example, if a feature used in the model is highly correlated with the outcome or target variable (e.g., using \"total sales\" to predict \"profit\"), it can cause leakage.\n",
    "\n",
    "In summary, **data leakage** is a broader term that refers to any unintended inclusion of information that would not be available at the time of prediction, whether it’s about future events or about the target variable itself.\n",
    "\n",
    "### **Look-ahead Bias**:\n",
    "Look-ahead bias is a specific form of data leakage that happens in **time-series data**, like financial datasets. It occurs when the model is trained using information from the future that wouldn't be available at the time the predictions are made. For example, in a stock market dataset, if the model uses future stock prices or returns to predict current stock prices, it will result in look-ahead bias because the model is using future information to predict the past.\n",
    "\n",
    "In summary, **look-ahead bias** specifically deals with improper handling of temporal sequences, where future data is mistakenly made available to the model during training, violating the natural time-ordering of events.\n",
    "\n",
    "### Key Differences:\n",
    "- **Scope**: Data leakage can occur in any type of data (not necessarily time-series), while look-ahead bias is specific to time-series or datasets where time-ordering is crucial (like in finance).\n",
    "- **Nature of Information**: Look-ahead bias deals specifically with the use of future information to predict past or current outcomes, whereas data leakage can refer to any kind of improper data use, including correlations or other relationships that shouldn’t be accessible to the model.\n",
    "\n",
    "Both are critical to avoid, especially in financial modeling, because they can lead to misleading performance estimates and overfitting, making models appear more accurate than they actually are in practice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 Take a pair of matrices (X, y), representing observed features and labels. These could be one of the datasets derived from the exercises in Chapter 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "X, Y = f_ch8.getTestData(n_features=6, n_informative=2, n_redundant=3, n_samples=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Derive the performance from a 10-fold CV of an RF classifier on (X, y), without shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# usual RF\n",
    "clf0 = RandomForestClassifier(\n",
    "    n_estimators=1_000,  # 1_000 trees\n",
    "    class_weight=\"balanced_subsample\",  # prevent minority class from being ignored\n",
    "    criterion=\"entropy\"  # information gain\n",
    ")\n",
    "\n",
    "# Ensemble of estimators with base estimator as a decision tree\n",
    "clf1 = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",  # information gain\n",
    "    max_features=\"sqrt\",  # sqrt(n_features) to force diversity among trees\n",
    "    class_weight=\"balanced\"  # prevent minority class from being ignored\n",
    ")\n",
    "clf1 = BaggingClassifier(\n",
    "    estimator=clf1,  # base estimator\n",
    "    n_estimators=1_000,  # 1_000 trees\n",
    "    max_samples=0.94,  # average uniqueness\n",
    "    max_features=1.0  # all features for bagging\n",
    ")\n",
    "\n",
    "# Bagging classifier on RF where max_samples is set to average uniqueness\n",
    "clf2 = RandomForestClassifier(\n",
    "    n_estimators=1,  # 1 tree\n",
    "    criterion=\"entropy\",  # information gain\n",
    "    bootstrap=False,  # no bootstrap\n",
    "    class_weight=\"balanced_subsample\"  # prevent minority class from being ignored\n",
    ")\n",
    "\n",
    "clf2 = BaggingClassifier(\n",
    "    estimator=clf2,  # base estimator\n",
    "    n_estimators=1_000,  # 1_000 trees\n",
    "    max_samples=0.94,  # average uniqueness\n",
    "    max_features=1.0  # all features for bagging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Y is correctly defined\n",
    "sample_weights = Y['w']\n",
    "t1 = Y['t1']\n",
    "Y = Y['bin']\n",
    "classifiers = [clf0, clf1, clf2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "# Create a KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "# Perform 10-fold cross-validation without shuffling\n",
    "for clf in classifiers:\n",
    "    print(\"Classifier:\", clf)\n",
    "    cv_scores = cross_val_score(clf, X, Y, cv=kf, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"Accuracy for each fold: {cv_scores}\")\n",
    "    print(f\"Mean accuracy: {np.mean(cv_scores):.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "# Create a KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def evaluate_classifier(clf, X, Y, cv):\n",
    "    cv_scores = cross_val_score(clf, X, Y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"Classifier: {clf}\")\n",
    "    print(f\"Accuracy for each fold: {cv_scores}\")\n",
    "    print(f\"Mean accuracy: {np.mean(cv_scores):.4f}\\n\")\n",
    "    return cv_scores\n",
    "\n",
    "# Run the classifiers in parallel\n",
    "results = Parallel(n_jobs=-1)(delayed(evaluate_classifier)(clf, X, Y, kf) for clf in classifiers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Derive the performance from a 10-fold CV of an RF on (X, y), with shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "# Create a KFold cross-validator\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def evaluate_classifier(clf, X, Y, cv):\n",
    "    cv_scores = cross_val_score(clf, X, Y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"Classifier: {clf}\")\n",
    "    print(f\"Accuracy for each fold: {cv_scores}\")\n",
    "    print(f\"Mean accuracy: {np.mean(cv_scores):.4f}\\n\")\n",
    "    return cv_scores\n",
    "\n",
    "# Run the classifiers in parallel\n",
    "results = Parallel(n_jobs=-1)(delayed(evaluate_classifier)(clf, X, Y, kf) for clf in classifiers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Take the same pair of matrices (X, y) you used in exercise 2.\n",
    "### (a) Derive the performance from a 10-fold purged CV of an RF on (X, y), with 1% embargo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf2\n",
    "f_ch7.cvScore(clf, X, Y, \n",
    "              sample_weight=sample_weights,\n",
    "              scoring='accuracy', \n",
    "              t1=t1, cv=10, \n",
    "              pctEmbargo=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ch4.main(t1, sLength=250, uniqueObj=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financial_math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
